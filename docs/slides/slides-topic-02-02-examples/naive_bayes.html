<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>QTM 350 Data Science Computing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
      <a href="../../index.html" class="sidebar-logo-link">
      <img src="../../images/course_image_2.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main">
    <a href="https://github.com/davi-moreira/2024S_dsc_emory_qtm_350" title="GitHub" class="quarto-navigation-tool px-1" aria-label="GitHub"><i class="bi bi-github"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../syllabus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Syllabus</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../schedule.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Schedule</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Materials</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../topics-pages/page-topic-01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Topic 1: Intro</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../topics-pages/page-topic-02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Topic 2: Version Control</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#todays-summary-and-learning-objectives" id="toc-todays-summary-and-learning-objectives" class="nav-link active" data-scroll-target="#todays-summary-and-learning-objectives">Today’s Summary and Learning Objectives</a>
  <ul class="collapse">
  <li><a href="#lets-embark-on-a-journey-through-the-realms-of-probability-statistics-and-machine-learning" id="toc-lets-embark-on-a-journey-through-the-realms-of-probability-statistics-and-machine-learning" class="nav-link" data-scroll-target="#lets-embark-on-a-journey-through-the-realms-of-probability-statistics-and-machine-learning">Let’s embark on a journey through the realms of probability, statistics, and machine learning!</a></li>
  <li><a href="#what-is-a-classification-problem-and-why-do-we-use-machine-learning-in-classification" id="toc-what-is-a-classification-problem-and-why-do-we-use-machine-learning-in-classification" class="nav-link" data-scroll-target="#what-is-a-classification-problem-and-why-do-we-use-machine-learning-in-classification">What is a Classification Problem and Why do we use Machine Learning in Classification?</a></li>
  <li><a href="#real-world-examples" id="toc-real-world-examples" class="nav-link" data-scroll-target="#real-world-examples">Real-World Examples</a></li>
  <li><a href="#advantages-of-machine-learning-for-classification" id="toc-advantages-of-machine-learning-for-classification" class="nav-link" data-scroll-target="#advantages-of-machine-learning-for-classification">Advantages of Machine Learning for Classification</a></li>
  </ul></li>
  <li><a href="#what-is-naive-bayes" id="toc-what-is-naive-bayes" class="nav-link" data-scroll-target="#what-is-naive-bayes">What is Naive Bayes?</a></li>
  <li><a href="#the-origins-of-bayes-theorem" id="toc-the-origins-of-bayes-theorem" class="nav-link" data-scroll-target="#the-origins-of-bayes-theorem">The Origins of Bayes’ Theorem</a></li>
  <li><a href="#bayes-theorem" id="toc-bayes-theorem" class="nav-link" data-scroll-target="#bayes-theorem">Bayes’ Theorem</a></li>
  <li><a href="#understanding-conditional-probability" id="toc-understanding-conditional-probability" class="nav-link" data-scroll-target="#understanding-conditional-probability">Understanding Conditional Probability</a></li>
  <li><a href="#what-is-joint-probability" id="toc-what-is-joint-probability" class="nav-link" data-scroll-target="#what-is-joint-probability">What is Joint Probability?</a></li>
  <li><a href="#symmetry-in-joint-events" id="toc-symmetry-in-joint-events" class="nav-link" data-scroll-target="#symmetry-in-joint-events">Symmetry in Joint Events</a></li>
  <li><a href="#deriving-bayes-theorem" id="toc-deriving-bayes-theorem" class="nav-link" data-scroll-target="#deriving-bayes-theorem">Deriving Bayes’ Theorem</a>
  <ul class="collapse">
  <li><a href="#from-conditional-probability-to-bayes-theorem" id="toc-from-conditional-probability-to-bayes-theorem" class="nav-link" data-scroll-target="#from-conditional-probability-to-bayes-theorem">From Conditional Probability to Bayes’ Theorem</a></li>
  </ul></li>
  <li><a href="#why-bayes-theorem-matters" id="toc-why-bayes-theorem-matters" class="nav-link" data-scroll-target="#why-bayes-theorem-matters">Why Bayes’ Theorem Matters?</a>
  <ul class="collapse">
  <li><a href="#example-medical-diagnosis" id="toc-example-medical-diagnosis" class="nav-link" data-scroll-target="#example-medical-diagnosis">Example: Medical Diagnosis</a>
  <ul class="collapse">
  <li><a href="#what-is-the-probability-that-a-person-has-the-disease-if-they-tested-positive" id="toc-what-is-the-probability-that-a-person-has-the-disease-if-they-tested-positive" class="nav-link" data-scroll-target="#what-is-the-probability-that-a-person-has-the-disease-if-they-tested-positive">What is the probability that a person has the disease if they tested positive?</a></li>
  </ul></li>
  <li><a href="#understanding-our-priors" id="toc-understanding-our-priors" class="nav-link" data-scroll-target="#understanding-our-priors">Understanding Our Priors</a></li>
  <li><a href="#applying-bayes-theorem" id="toc-applying-bayes-theorem" class="nav-link" data-scroll-target="#applying-bayes-theorem">Applying Bayes’ Theorem</a></li>
  <li><a href="#finding-ppos" id="toc-finding-ppos" class="nav-link" data-scroll-target="#finding-ppos">Finding <span class="math inline">\(P(Pos)\)</span></a></li>
  <li><a href="#the-posterior-probability" id="toc-the-posterior-probability" class="nav-link" data-scroll-target="#the-posterior-probability">The Posterior Probability</a></li>
  <li><a href="#applying-bayes-theorem-for-classification" id="toc-applying-bayes-theorem-for-classification" class="nav-link" data-scroll-target="#applying-bayes-theorem-for-classification">Applying Bayes’ Theorem for Classification</a>
  <ul class="collapse">
  <li><a href="#how-do-we-deal-with-x-being-multidimensional" id="toc-how-do-we-deal-with-x-being-multidimensional" class="nav-link" data-scroll-target="#how-do-we-deal-with-x-being-multidimensional">How do we deal with <span class="math inline">\(X\)</span> being multidimensional?</a></li>
  </ul></li>
  <li><a href="#the-complexity-of-high-dimensionality" id="toc-the-complexity-of-high-dimensionality" class="nav-link" data-scroll-target="#the-complexity-of-high-dimensionality">The Complexity of High Dimensionality</a></li>
  <li><a href="#example-the-challenge-of-high-dimensionality-in-spam-detection" id="toc-example-the-challenge-of-high-dimensionality-in-spam-detection" class="nav-link" data-scroll-target="#example-the-challenge-of-high-dimensionality-in-spam-detection">Example: The Challenge of High Dimensionality in Spam Detection</a></li>
  <li><a href="#multidimensional-features" id="toc-multidimensional-features" class="nav-link" data-scroll-target="#multidimensional-features">Multidimensional Features</a></li>
  <li><a href="#example-the-challenge-of-high-dimensionality-in-spam-detection-1" id="toc-example-the-challenge-of-high-dimensionality-in-spam-detection-1" class="nav-link" data-scroll-target="#example-the-challenge-of-high-dimensionality-in-spam-detection-1">Example: The Challenge of High Dimensionality in Spam Detection</a></li>
  <li><a href="#complexity-of-direct-calculation-pxc_k" id="toc-complexity-of-direct-calculation-pxc_k" class="nav-link" data-scroll-target="#complexity-of-direct-calculation-pxc_k">Complexity of Direct Calculation <span class="math inline">\(P(X|C_k)\)</span></a></li>
  </ul></li>
  <li><a href="#the-naive-assumption" id="toc-the-naive-assumption" class="nav-link" data-scroll-target="#the-naive-assumption">The Naive Assumption</a></li>
  <li><a href="#the-naive-bayes-classifier" id="toc-the-naive-bayes-classifier" class="nav-link" data-scroll-target="#the-naive-bayes-classifier">The Naive Bayes Classifier</a></li>
  <li><a href="#importance-in-machine-learning" id="toc-importance-in-machine-learning" class="nav-link" data-scroll-target="#importance-in-machine-learning">Importance in Machine Learning</a>
  <ul class="collapse">
  <li><a href="#where-is-naive-bayes-used" id="toc-where-is-naive-bayes-used" class="nav-link" data-scroll-target="#where-is-naive-bayes-used">Where is Naive Bayes Used?</a></li>
  </ul></li>
  <li><a href="#statistical-learning-models" id="toc-statistical-learning-models" class="nav-link" data-scroll-target="#statistical-learning-models">Statistical Learning Models</a>
  <ul class="collapse">
  <li><a href="#supervised-learning" id="toc-supervised-learning" class="nav-link" data-scroll-target="#supervised-learning">Supervised Learning</a>
  <ul class="collapse">
  <li><a href="#examples" id="toc-examples" class="nav-link" data-scroll-target="#examples">Examples</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#statistical-learning-models-1" id="toc-statistical-learning-models-1" class="nav-link" data-scroll-target="#statistical-learning-models-1">Statistical learning models</a>
  <ul class="collapse">
  <li><a href="#unsupervised-learning" id="toc-unsupervised-learning" class="nav-link" data-scroll-target="#unsupervised-learning">Unsupervised Learning</a>
  <ul class="collapse">
  <li><a href="#examples-1" id="toc-examples-1" class="nav-link" data-scroll-target="#examples-1">Examples</a></li>
  </ul></li>
  <li><a href="#generative-vs.-discriminative-models" id="toc-generative-vs.-discriminative-models" class="nav-link" data-scroll-target="#generative-vs.-discriminative-models">Generative vs.&nbsp;Discriminative Models</a>
  <ul class="collapse">
  <li><a href="#generative-models" id="toc-generative-models" class="nav-link" data-scroll-target="#generative-models">Generative Models</a></li>
  <li><a href="#discriminative-models" id="toc-discriminative-models" class="nav-link" data-scroll-target="#discriminative-models">Discriminative Models</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#naive-bayes-as-a-generative-model" id="toc-naive-bayes-as-a-generative-model" class="nav-link" data-scroll-target="#naive-bayes-as-a-generative-model">Naive Bayes as a Generative Model</a>
  <ul class="collapse">
  <li><a href="#why-generative" id="toc-why-generative" class="nav-link" data-scroll-target="#why-generative">Why Generative?</a></li>
  <li><a href="#the-role-of-naive-bayes-in-machine-learning" id="toc-the-role-of-naive-bayes-in-machine-learning" class="nav-link" data-scroll-target="#the-role-of-naive-bayes-in-machine-learning">The Role of Naive Bayes in Machine Learning</a></li>
  <li><a href="#overview-of-naive-bayes-classifiers" id="toc-overview-of-naive-bayes-classifiers" class="nav-link" data-scroll-target="#overview-of-naive-bayes-classifiers">Overview of Naive Bayes Classifiers</a></li>
  </ul></li>
  <li><a href="#gaussian-naive-bayes-1" id="toc-gaussian-naive-bayes-1" class="nav-link" data-scroll-target="#gaussian-naive-bayes-1">Gaussian Naive Bayes</a>
  <ul class="collapse">
  <li><a href="#formula" id="toc-formula" class="nav-link" data-scroll-target="#formula">Formula:</a></li>
  </ul></li>
  <li><a href="#multinomial-naive-bayes-1" id="toc-multinomial-naive-bayes-1" class="nav-link" data-scroll-target="#multinomial-naive-bayes-1">Multinomial Naive Bayes</a></li>
  <li><a href="#bernoulli-naive-bayes-1" id="toc-bernoulli-naive-bayes-1" class="nav-link" data-scroll-target="#bernoulli-naive-bayes-1">Bernoulli Naive Bayes</a>
  <ul class="collapse">
  <li><a href="#choosing-the-right-naive-bayes-classifier" id="toc-choosing-the-right-naive-bayes-classifier" class="nav-link" data-scroll-target="#choosing-the-right-naive-bayes-classifier">Choosing the Right Naive Bayes Classifier</a>
  <ul class="collapse">
  <li><a href="#selection-strategy" id="toc-selection-strategy" class="nav-link" data-scroll-target="#selection-strategy">Selection Strategy</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#measuring-performance" id="toc-measuring-performance" class="nav-link" data-scroll-target="#measuring-performance">Measuring Performance</a>
  <ul class="collapse">
  <li><a href="#measuring-performance-1" id="toc-measuring-performance-1" class="nav-link" data-scroll-target="#measuring-performance-1">Measuring Performance</a></li>
  <li><a href="#measuring-performance-2" id="toc-measuring-performance-2" class="nav-link" data-scroll-target="#measuring-performance-2">Measuring Performance</a></li>
  <li><a href="#measuring-performance-3" id="toc-measuring-performance-3" class="nav-link" data-scroll-target="#measuring-performance-3">Measuring Performance</a></li>
  <li><a href="#understanding-model-performance" id="toc-understanding-model-performance" class="nav-link" data-scroll-target="#understanding-model-performance">Understanding Model Performance</a></li>
  <li><a href="#practice-gaussian-naive-bayes" id="toc-practice-gaussian-naive-bayes" class="nav-link" data-scroll-target="#practice-gaussian-naive-bayes">Practice: Gaussian Naive Bayes</a></li>
  <li><a href="#pima-indians-diabetes-database-overview" id="toc-pima-indians-diabetes-database-overview" class="nav-link" data-scroll-target="#pima-indians-diabetes-database-overview">Pima Indians Diabetes Database Overview</a>
  <ul class="collapse">
  <li><a href="#context" id="toc-context" class="nav-link" data-scroll-target="#context">Context</a></li>
  <li><a href="#content" id="toc-content" class="nav-link" data-scroll-target="#content">Content</a></li>
  <li><a href="#step-0-import-libraries-and-dataset" id="toc-step-0-import-libraries-and-dataset" class="nav-link" data-scroll-target="#step-0-import-libraries-and-dataset">Step 0: Import libraries and Dataset</a></li>
  <li><a href="#step-1-descriptive-statistics" id="toc-step-1-descriptive-statistics" class="nav-link" data-scroll-target="#step-1-descriptive-statistics">Step 1: Descriptive Statistics</a></li>
  <li><a href="#observations" id="toc-observations" class="nav-link" data-scroll-target="#observations">Observations:</a></li>
  <li><a href="#observations-1" id="toc-observations-1" class="nav-link" data-scroll-target="#observations-1">Observations:</a></li>
  <li><a href="#step-2-data-preprocessing" id="toc-step-2-data-preprocessing" class="nav-link" data-scroll-target="#step-2-data-preprocessing">Step 2: Data Preprocessing</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#step-3-data-modelling" id="toc-step-3-data-modelling" class="nav-link" data-scroll-target="#step-3-data-modelling">Step 3: Data Modelling</a></li>
  <li><a href="#step-4-model-evaluation" id="toc-step-4-model-evaluation" class="nav-link" data-scroll-target="#step-4-model-evaluation">Step 4: Model Evaluation</a></li>
  <li><a href="#practice-multinomial-naive-bayes" id="toc-practice-multinomial-naive-bayes" class="nav-link" data-scroll-target="#practice-multinomial-naive-bayes">Practice: Multinomial Naive Bayes</a>
  <ul class="collapse">
  <li><a href="#practice-multinomial-naive-bayes-1" id="toc-practice-multinomial-naive-bayes-1" class="nav-link" data-scroll-target="#practice-multinomial-naive-bayes-1">Practice: Multinomial Naive Bayes</a></li>
  <li><a href="#bbc-full-text-document-classification" id="toc-bbc-full-text-document-classification" class="nav-link" data-scroll-target="#bbc-full-text-document-classification">BBC Full Text Document Classification</a>
  <ul class="collapse">
  <li><a href="#context-1" id="toc-context-1" class="nav-link" data-scroll-target="#context-1">Context</a></li>
  <li><a href="#step-0-import-libraries-and-dataset-1" id="toc-step-0-import-libraries-and-dataset-1" class="nav-link" data-scroll-target="#step-0-import-libraries-and-dataset-1">Step 0: Import Libraries and Dataset</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#step-1-descriptive-statistics-1" id="toc-step-1-descriptive-statistics-1" class="nav-link" data-scroll-target="#step-1-descriptive-statistics-1">Step 1: Descriptive Statistics</a></li>
  <li><a href="#step-2-data-preprocessing-1" id="toc-step-2-data-preprocessing-1" class="nav-link" data-scroll-target="#step-2-data-preprocessing-1">Step 2: Data Preprocessing</a></li>
  <li><a href="#step-4-data-modeling" id="toc-step-4-data-modeling" class="nav-link" data-scroll-target="#step-4-data-modeling">Step 4: Data Modeling</a></li>
  <li><a href="#not-covered-in-the-lecture" id="toc-not-covered-in-the-lecture" class="nav-link" data-scroll-target="#not-covered-in-the-lecture">Not covered in the lecture:</a></li>
  <li><a href="#annex" id="toc-annex" class="nav-link" data-scroll-target="#annex">Annex</a>
  <ul class="collapse">
  <li><a href="#complement-naive-bayes" id="toc-complement-naive-bayes" class="nav-link" data-scroll-target="#complement-naive-bayes">Complement Naive Bayes</a></li>
  <li><a href="#categorical-naive-bayes" id="toc-categorical-naive-bayes" class="nav-link" data-scroll-target="#categorical-naive-bayes">Categorical Naive Bayes</a></li>
  <li><a href="#out-of-core-naive-bayes-model-fitting" id="toc-out-of-core-naive-bayes-model-fitting" class="nav-link" data-scroll-target="#out-of-core-naive-bayes-model-fitting">Out-of-core naive Bayes model fitting</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">




<div>
<p><img src="naive_bayes_files/figure-html/454e37d3-1-bayes_theorem.png" width="300"></p>
</div>
<p><br></p>
#
<center>
Naive Bayes Classifiers
</center>
##
<center>
Davi Moreira
</center>
###
<center>
Quantitative Theory and Methods
</center>
###
<center>
Emory University
</center>
<section id="todays-summary-and-learning-objectives" class="level1">
<h1>Today’s Summary and Learning Objectives</h1>
<ol type="1">
<li><p><strong>Statistical Foundations</strong> of Naive Bayes Classifiers.</p>
<pre><code> - The beauty of Bayes Theorem in action;
 - The Naive Bayes assumptions;
 - Three versions of Naive Bayes:
         - Gaussian Naive Bayes.
         - Multinomial Naive Bayes.
         - Bernoulli Naive Bayes.</code></pre></li>
</ol>
<blockquote class="blockquote">
<p>“Knowing the underlying statistics allows us to <strong>implement and interpret model outputs</strong> more effectively.”</p>
</blockquote>
<ol start="2" type="1">
<li><p>Naive Bayes Classifiers <strong>Implementation in <code>Python</code></strong>.</p>
<pre><code> - Beyond theory, we will apply Machine Learning in real-world classification problems.
 - Why Python? A versatile tool for data science and machine learning.
 - Libraries Make Life Easier: Utilizing NumPy, pandas, and scikit-learn for Naive Bayes.</code></pre></li>
</ol>
<blockquote class="blockquote">
<p>“Understanding the code and computational aspects enables us to <strong>apply Naive Bayes to real-world problems</strong> efficiently.”</p>
</blockquote>
<section id="lets-embark-on-a-journey-through-the-realms-of-probability-statistics-and-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="lets-embark-on-a-journey-through-the-realms-of-probability-statistics-and-machine-learning">Let’s embark on a journey through the realms of probability, statistics, and machine learning!</h3>
#
<center>
What is a classification problem?
</center>
#
<center>
Why do we use Machine Learning in Classification?
</center>
</section>
<section id="what-is-a-classification-problem-and-why-do-we-use-machine-learning-in-classification" class="level2">
<h2 class="anchored" data-anchor-id="what-is-a-classification-problem-and-why-do-we-use-machine-learning-in-classification">What is a Classification Problem and Why do we use Machine Learning in Classification?</h2>
<p>Classification involves categorizing data into predefined classes or groups based on their features. The goal is to accurately assign new data points to one of these categories.</p>
</section>
<section id="real-world-examples" class="level2">
<h2 class="anchored" data-anchor-id="real-world-examples">Real-World Examples</h2>
<ul>
<li><strong>Business</strong>: From customer segmentation to fraud detection, classification drives smarter business decisions.</li>
<li><strong>Healthcare</strong>: Predicting disease outbreaks, patient diagnosis, and treatment planning.</li>
<li><strong>Technology</strong>: Image and Voice recognition.</li>
<li><strong>Political Science</strong>: Policy Expressed Agendas.</li>
</ul>
</section>
<section id="advantages-of-machine-learning-for-classification" class="level2">
<h2 class="anchored" data-anchor-id="advantages-of-machine-learning-for-classification">Advantages of Machine Learning for Classification</h2>
<ul>
<li><strong>Efficiency at Scale</strong>: Machine learning algorithms can quickly classify large volumes of data with high accuracy.</li>
<li><strong>Pattern Recognition</strong>: ML models excel at recognizing complex patterns in data that are not easily discernible by humans.</li>
<li><strong>Adaptability</strong>: ML classifiers can adapt to new, unseen data, making them ideal for dynamic environments.</li>
<li><strong>Automation</strong>: Automates the decision-making process in real-time applications, like spam detection or medical diagnoses.</li>
<li><strong>Continuous Improvement</strong>: ML models can learn from new data over time, improving their accuracy and robustness.</li>
</ul>
<p>Machine learning has transformed the landscape of classification, providing tools that offer precision, speed, and flexibility, which are unparalleled by traditional human and statistical methods.</p>
#
<center>
What is Naive Bayes?
</center>
</section>
</section>
<section id="what-is-naive-bayes" class="level1">
<h1>What is Naive Bayes?</h1>
<p><br></p>
<ul>
<li><p>A probabilistic machine learning model based on Bayes’ Theorem.</p></li>
<li><p>Assumes independence among predictors.</p></li>
<li><p>Simple yet powerful for classification tasks.</p></li>
</ul>
</section>
<section id="the-origins-of-bayes-theorem" class="level1">
<h1>The Origins of Bayes’ Theorem</h1>
<p><br></p>
<ul>
<li><p>Developed by the English statistician Thomas Bayes (1701–1761).</p></li>
<li><p>Bayes’ Theorem describes the probability of an event, based on prior knowledge of conditions that might be related to the event.</p></li>
</ul>
</section>
<section id="bayes-theorem" class="level1">
<h1><a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes’ Theorem</a></h1>
<p><span class="math display">\[ P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)} \]</span></p>
<ul>
<li><span class="math inline">\(P(A|B)\)</span> is the <strong>posterior probability</strong>: Probability of event A occurring given that B is true - updated probability after the evidence is considered.</li>
<li><span class="math inline">\(P(A)\)</span> is the <strong>prior probability</strong>: Initial probability of event A - the probability before the evidence is considered.</li>
<li><span class="math inline">\(P(B|A)\)</span> is the <strong>likelihood</strong>: Probability of observing event B given that A is true.</li>
<li><span class="math inline">\(P(B)\)</span> is the <strong>marginal probability</strong>: Total probability of the evidence, event B.</li>
</ul>
</section>
<section id="understanding-conditional-probability" class="level1">
<h1>Understanding Conditional Probability</h1>
<p><br></p>
<p>Conditional probability is the probability of an event occurring given that another event has already occurred.</p>
<ul>
<li><strong>Definition</strong>: <span class="math display">\[ P(A|B) = \frac{P(A \cap B)}{P(B)} \]</span> is the probability of event A occurring given that B is true.</li>
</ul>
<p><br></p>
<ul>
<li><strong>Interpretation</strong>: How likely is A if we know that B happens?</li>
</ul>
</section>
<section id="what-is-joint-probability" class="level1">
<h1>What is Joint Probability?</h1>
<p>Joint probability refers to the probability of two events occurring together.</p>
<ul>
<li><strong>Definition</strong>: <span class="math inline">\(P(A \cap B)\)</span> is the probability that both A and B occur.</li>
<li><strong>Relation to Conditional Probability</strong>:</li>
</ul>
<p><span class="math display">\[ P(A \cap B) = P(A|B) \cdot P(B) \]</span> <span class="math display">\[ P(B \cap A) = P(B|A) \cdot P(A) \]</span></p>
<p>This formula is crucial for understanding Bayes’ Theorem.</p>
</section>
<section id="symmetry-in-joint-events" class="level1">
<h1>Symmetry in Joint Events</h1>
<p>Joint probability is symmetric, meaning:</p>
<p><span class="math display">\[ P(A \cap B) = P(B \cap A) \]</span></p>
<p>Thus, we can also express it as:</p>
<p><span class="math display">\[ P(A \cap B) = P(B|A) \cdot P(A) \]</span></p>
<p>This symmetry is the key to deriving Bayes’ Theorem.</p>
</section>
<section id="deriving-bayes-theorem" class="level1">
<h1>Deriving Bayes’ Theorem</h1>
<section id="from-conditional-probability-to-bayes-theorem" class="level2">
<h2 class="anchored" data-anchor-id="from-conditional-probability-to-bayes-theorem">From Conditional Probability to Bayes’ Theorem</h2>
<p>Given that the definition of Conditional Probability is:</p>
<p><span class="math display">\[ P(A|B) = \frac{P(A \cap B)}{P(B)} \]</span></p>
<p>And knowing:</p>
<p><span class="math display">\[ P(A \cap B) = P(B|A) \cdot P(A) \]</span></p>
<p>We can substitute to get:</p>
<p><span class="math display">\[ P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)} \]</span></p>
###
<center>
<strong>This is Bayes’ Theorem!</strong>
</center>
</section>
</section>
<section id="why-bayes-theorem-matters" class="level1">
<h1>Why Bayes’ Theorem Matters?</h1>
<p><br></p>
<p>Bayes’ Theorem is a foundational principle in probability theory and statistics, enabling:</p>
<ul>
<li><p><strong>Incorporaton of Prior Knowledge</strong>: It allows for the integration of prior knowledge or beliefs when making statistical inferences.</p></li>
<li><p><strong>Beliefs Update</strong>: It provides a systematic way to update the probability estimates as new evidence or data becomes available.</p></li>
<li><p><strong>Probabilistic Thinking</strong>: Encourages a probabilistic approach to decision making, quantifying uncertainty, and reasoning under uncertainty.</p></li>
<li><p><strong>Versatility in Applications</strong>: From medical diagnosis to spam filtering, Bayes’ Theorem is pivotal in areas requiring probabilistic assessment.</p></li>
</ul>
<p><a href="https://www.sciencedirect.com/topics/mathematics/bayesian-paradigm#:~:text=Bayesian%20Methodology%20in%20Statistics&amp;text=By%20using%20probability%20distributions%20to,coherence%20of%20the%20proposed%20solutions.">Bayes’ Theorem is a paradigm</a> that shapes the way we interpret and interact with data, offering a powerful tool for learning from information and making decisions in an uncertain world.</p>
<section id="example-medical-diagnosis" class="level2">
<h2 class="anchored" data-anchor-id="example-medical-diagnosis">Example: Medical Diagnosis</h2>
<section id="what-is-the-probability-that-a-person-has-the-disease-if-they-tested-positive" class="level3">
<h3 class="anchored" data-anchor-id="what-is-the-probability-that-a-person-has-the-disease-if-they-tested-positive">What is the probability that a person has the disease if they tested positive?</h3>
<p><br></p>
<p>Consider a test for a particular disease, which has the following characteristics:</p>
<p><br></p>
<ul>
<li><strong>Disease Prevalence (Prior Probability)</strong>: 0.1%, <span class="math inline">\(P(Disease) = 0.001\)</span>.</li>
</ul>
<p><br></p>
<ul>
<li><strong>Test Sensitivity (True Positive Rate)</strong>: 99%, <span class="math inline">\(P(Pos | Disease) = 0.99\)</span>.</li>
</ul>
<p><br></p>
<ul>
<li><strong>Test Specificity (True Negative Rate)</strong>: 95%, <span class="math inline">\(P(Neg | NoDisease) = 0.95\)</span>.</li>
</ul>
</section>
</section>
<section id="understanding-our-priors" class="level2">
<h2 class="anchored" data-anchor-id="understanding-our-priors">Understanding Our Priors</h2>
<p><br></p>
<ul>
<li><strong>Prior Probability of Having the Disease</strong>: <span class="math inline">\(P(Disease) = 0.001\)</span></li>
</ul>
<p><br></p>
<ul>
<li><strong>Prior Probability of Not Having the Disease</strong>: <span class="math inline">\(P(NoDisease) = 1 - P(Disease) = 0.999\)</span></li>
</ul>
<p><br></p>
<p>These priors are essential for our Bayes’ Theorem calculation.</p>
</section>
<section id="applying-bayes-theorem" class="level2">
<h2 class="anchored" data-anchor-id="applying-bayes-theorem">Applying Bayes’ Theorem</h2>
<p><br></p>
<p>To find the posterior probability <span class="math inline">\(P(Disease | Pos)\)</span>, we apply Bayes’ Theorem:</p>
<p><span class="math display">\[ P(Disease | Pos) = \frac{P(Pos | Disease) \cdot P(Disease)}{P(Pos)} \]</span></p>
<p><br></p>
<p>Where <span class="math inline">\(P(Pos)\)</span> can be found using the <a href="https://en.wikipedia.org/wiki/Law_of_total_probability">law of total probability</a>:</p>
<p><span class="math display">\[ P(Pos) = P(Pos | Disease) \cdot P(Disease) + P(Pos | NoDisease) \cdot P(NoDisease) \]</span></p>
<blockquote class="blockquote">
<p>The law of total probability is a fundamental rule relating marginal probabilities to conditional probabilities. It states that the probability of an event can be found by considering all possible ways that the event can occur.</p>
</blockquote>
</section>
<section id="finding-ppos" class="level2">
<h2 class="anchored" data-anchor-id="finding-ppos">Finding <span class="math inline">\(P(Pos)\)</span></h2>
<p><br></p>
<p>Given our test specificity is 95%, the false positive rate is 5% (<span class="math inline">\(P(Pos | NoDisease) = 0.05\)</span>).</p>
<p><span class="math display">\[ P(Pos) = (0.99 \times 0.001) + (0.05 \times 0.999) \]</span> <span class="math display">\[ P(Pos) = 0.051 \]</span></p>
</section>
<section id="the-posterior-probability" class="level2">
<h2 class="anchored" data-anchor-id="the-posterior-probability">The Posterior Probability</h2>
<p><br></p>
<ul>
<li><strong>Given</strong>: <span class="math inline">\(P(Pos | Disease) = 0.99\)</span>, <span class="math inline">\(P(Disease) = 0.001\)</span>, and our calculated <span class="math inline">\(P(Pos) = 0.051\)</span>.</li>
</ul>
<p><br></p>
<p><span class="math display">\[ P(Disease | Pos) = \frac{0.99 \times 0.001}{0.051 } \]</span></p>
<p><br></p>
<p><span class="math display">\[ P(Disease | Pos) = 0.019 \]</span></p>
<p>Despite testing positive, <strong>an individual has only a <span class="math inline">\(1.9\%\)</span> chance of having the disease</strong>. This result might seem counterintuitive given the high test sensitivity (99%), but it is largely due to the low prevalence of the disease (0.1%) and the impact of false positives in the wider population.</p>
<blockquote class="blockquote">
<p><strong>Implications</strong>: This underscores a crucial aspect of diagnostic tests - a high sensitivity rate does not guarantee a high probability of having the disease upon testing positive, especially when the disease prevalence is low. The relatively low posterior probability highlights the importance of considering both the characteristics of the test (such as sensitivity and specificity) and the prevalence of the condition in the population when interpreting test results.</p>
</blockquote>
#
<center>
Applying Bayes’ Theorem for Classification
</center>
</section>
<section id="applying-bayes-theorem-for-classification" class="level2">
<h2 class="anchored" data-anchor-id="applying-bayes-theorem-for-classification">Applying Bayes’ Theorem for Classification</h2>
<p><br></p>
<p>Given a set of features <span class="math inline">\(X = (x_1, x_2, ..., x_n)\)</span>, we want to predict the class <span class="math inline">\(C_k\)</span> out of <span class="math inline">\(m\)</span> possible classes.</p>
<p>The goal is to find:</p>
<p><span class="math display">\[ P(C_k|X) = \frac{P(X|C_k) \cdot P(C_k)}{P(X)} \]</span></p>
<ul>
<li><strong><span class="math inline">\(P(C_k|X)\)</span></strong> is the <strong>posterior probability</strong>: Probability of class <span class="math inline">\(C_k\)</span> given features <span class="math inline">\(X\)</span>.</li>
<li><strong><span class="math inline">\(P(C_k)\)</span></strong> is the <strong>prior probability</strong>: Probability of class <span class="math inline">\(C_k\)</span>.</li>
<li><strong><span class="math inline">\(P(X|C_k)\)</span></strong> is the <strong>likelihood</strong>: Likelihood of features <span class="math inline">\(X\)</span> given class <span class="math inline">\(C_k\)</span>.</li>
<li><strong><span class="math inline">\(P(X)\)</span></strong> is the <strong>marginal probability</strong>: Evidence, the total probability of observing features <span class="math inline">\(X\)</span>.</li>
</ul>
<section id="how-do-we-deal-with-x-being-multidimensional" class="level3">
<h3 class="anchored" data-anchor-id="how-do-we-deal-with-x-being-multidimensional">How do we deal with <span class="math inline">\(X\)</span> being multidimensional?</h3>
</section>
</section>
<section id="the-complexity-of-high-dimensionality" class="level2">
<h2 class="anchored" data-anchor-id="the-complexity-of-high-dimensionality">The Complexity of High Dimensionality</h2>
<p><br></p>
<p>When applying Bayes’ Theorem to classification:</p>
<p><br></p>
<ul>
<li>We encounter <strong>multidimensional feature vectors</strong> <span class="math inline">\(X = (x_1, x_2, ..., x_n)\)</span>.</li>
</ul>
<p><br></p>
<ul>
<li>Calculating the likelihood, <span class="math inline">\(P(X|C_k)\)</span>, directly becomes impractical due to the <strong>curse of dimensionality</strong>.</li>
</ul>
<p><br></p>
<ul>
<li>High-dimensional spaces increase the <strong>data requirement exponentially</strong>.</li>
</ul>
<p><br></p>
<ul>
<li><strong>Direct calculation</strong> of <span class="math inline">\(P(X|C_k)\)</span> involves understanding complex relationships among all features.</li>
</ul>
</section>
<section id="example-the-challenge-of-high-dimensionality-in-spam-detection" class="level2">
<h2 class="anchored" data-anchor-id="example-the-challenge-of-high-dimensionality-in-spam-detection">Example: The Challenge of High Dimensionality in Spam Detection</h2>
<p><br></p>
<ul>
<li><p><strong>Context</strong>: Email spam detection based on multidimensional feature vectors <span class="math inline">\(X = (x_1, x_2, ..., x_n)\)</span>.</p></li>
<li><p><strong>Goal</strong>: Classify emails into spam (<span class="math inline">\(C_1\)</span>) or not spam (<span class="math inline">\(C_2\)</span>).</p></li>
</ul>
</section>
<section id="multidimensional-features" class="level2">
<h2 class="anchored" data-anchor-id="multidimensional-features">Multidimensional Features</h2>
<ul>
<li>Frequency of specific keywords (e.g., “offer”, “free”).</li>
<li>Email length.</li>
<li>Use of capital letters.</li>
<li>Presence of attachments.</li>
<li>Time of day the email was sent.</li>
</ul>
<p>Each feature contributes to identifying spam.</p>
</section>
<section id="example-the-challenge-of-high-dimensionality-in-spam-detection-1" class="level2">
<h2 class="anchored" data-anchor-id="example-the-challenge-of-high-dimensionality-in-spam-detection-1">Example: The Challenge of High Dimensionality in Spam Detection</h2>
</section>
<section id="complexity-of-direct-calculation-pxc_k" class="level2">
<h2 class="anchored" data-anchor-id="complexity-of-direct-calculation-pxc_k">Complexity of Direct Calculation <span class="math inline">\(P(X|C_k)\)</span></h2>
<p><br></p>
<ul>
<li>Directly calculating <span class="math inline">\(P(X|C_k)\)</span> requires assessing how all features <span class="math inline">\(x_1, x_2, ..., x_n\)</span> collectively influence the likelihood of an email being spam.</li>
</ul>
<p><br></p>
<ul>
<li>With 10 binary features, there are <span class="math inline">\(2^{10} = 1024\)</span> possible combinations.</li>
</ul>
<p><br></p>
<ul>
<li>Accurately estimating <span class="math inline">\(P(X|C_k)\)</span> for all combinations requires a vast dataset, often impractical to obtain.</li>
</ul>
#
<center>
The Naive Assumption
</center>
</section>
</section>
<section id="the-naive-assumption" class="level1">
<h1>The Naive Assumption</h1>
<p>The Naive Bayes assumption simplifies the problem by assuming <strong>each feature <span class="math inline">\(x_i\)</span> is independent of every other feature</strong>.</p>
<p>This leads to:</p>
<p><span class="math display">\[ P(X|C_k) = P(x_1, x_2, ..., x_n|C_k) = \prod_{i=1}^{n} P(x_i|C_k) \]</span></p>
<p>Thus, our classifier becomes:</p>
<p><span class="math display">\[ P(C_k|X) = \frac{P(C_k) \prod_{i=1}^{n} P(x_i|C_k)}{P(X)} \]</span></p>
<ul>
<li><strong>Independence</strong>: Each feature <span class="math inline">\(x_i\)</span> is independent of every other feature given the class <span class="math inline">\(C_k\)</span>.</li>
<li>This assumption significantly reduces computational complexity.</li>
</ul>
#
<center>
The Naive Bayes Classifier
</center>
</section>
<section id="the-naive-bayes-classifier" class="level1">
<h1>The Naive Bayes Classifier</h1>
<p>Given the independence assumption, we can rewrite Bayes’ Theorem for our classification problem:</p>
<p><span class="math display">\[ P(C_k|X) = \frac{P(C_k) \prod_{i=1}^{n} P(x_i|C_k)}{P(X)} \]</span></p>
<ul>
<li><strong>Classification Decision</strong>: Since $P(X)=P(x_1, , x_n) $ is constant across all classes, we focus on the classification rule that maximize the numerator:</li>
</ul>
<p><span class="math display">\[
P(C_k \mid x_1, \dots, x_n) \propto P(C_k) \prod_{i=1}^{n} P(x_i \mid C_k)
\]</span> <span class="math display">\[
\Downarrow
\]</span></p>
<p><span class="math display">\[ \hat{C} = \arg \max_{C_k} P(C_k) \prod_{i=1}^{n} P(x_i|C_k) \]</span></p>
<p>$ P(C_k) $ is then the relative frequency of class $ C $ in the training set.</p>
</section>
<section id="importance-in-machine-learning" class="level1">
<h1>Importance in Machine Learning</h1>
<ul>
<li><strong>Efficiency</strong>: Fast to train and predict.</li>
<li><strong>Scalability</strong>: Works well with large datasets.</li>
<li><strong>Versatility</strong>: Handles both binary and multiclass classification problems.</li>
</ul>
<section id="where-is-naive-bayes-used" class="level2">
<h2 class="anchored" data-anchor-id="where-is-naive-bayes-used">Where is Naive Bayes Used?</h2>
<ul>
<li>Spam detection in emails.</li>
<li>Sentiment analysis in social media.</li>
<li>Document classification.</li>
<li>Medical diagnosis.</li>
</ul>
#
<center>
Statistical Learning Models
</center>
</section>
</section>
<section id="statistical-learning-models" class="level1">
<h1>Statistical Learning Models</h1>
<p><strong>Learning Paradigms</strong>: Statistical learning models can be broadly categorized into <strong>supervised and unsupervised</strong> learning based on the nature of the training data and the learning objectives.</p>
<section id="supervised-learning" class="level2">
<h2 class="anchored" data-anchor-id="supervised-learning">Supervised Learning</h2>
<p>Models are trained on labeled data. Each training example includes an input and a corresponding output label. The goal is to learn a mapping function from inputs to outputs to make predictions on new, unseen data.</p>
<section id="examples" class="level3">
<h3 class="anchored" data-anchor-id="examples">Examples</h3>
<ul>
<li><strong>Linear Regression</strong>: Predicts a continuous output. Common in predicting housing prices, stock market trends, etc.</li>
<li><strong>Naive Bayes Classifiers</strong>: Suitable for classification tasks like: image recognition, spam detection, and document categorization.</li>
<li><strong>Random Forests</strong>: Versatile for classification and regression tasks. Used in customer segmentation, medical diagnosis, and more.</li>
<li><strong>Support Vector Machines (SVM)</strong>: Effective in high-dimensional spaces for classification tasks such as image recognition and text categorization.</li>
</ul>
</section>
</section>
</section>
<section id="statistical-learning-models-1" class="level1">
<h1>Statistical learning models</h1>
<section id="unsupervised-learning" class="level2">
<h2 class="anchored" data-anchor-id="unsupervised-learning">Unsupervised Learning</h2>
<p>Models work with unlabeled data, focusing on identifying patterns, clusters, or relationships within the data without predefined labels.</p>
<section id="examples-1" class="level3">
<h3 class="anchored" data-anchor-id="examples-1">Examples</h3>
<ul>
<li><strong>K-Means Clustering</strong>: Identifies clusters within the data. Applied in market segmentation, gene sequence analysis, etc.</li>
<li><strong>Principal Component Analysis (PCA)</strong>: A dimensionality reduction technique used to reduce the dimensionality of large data sets.</li>
<li><strong>Topic Models (e.g., Latent Dirichlet Allocation - LDA)</strong>: Used to discover the abstract “topics” that occur in a collection of documents. Topic modeling is widely used in text mining for uncovering hidden thematic structures in text data, such as finding trends in scientific literature, organizing large archives of documents, or enhancing search engines.</li>
</ul>
</section>
</section>
<section id="generative-vs.-discriminative-models" class="level2">
<h2 class="anchored" data-anchor-id="generative-vs.-discriminative-models">Generative vs.&nbsp;Discriminative Models</h2>
<p>Within the supervised and unsupervised paradigm, models can be further categorized into generative and discriminative types:</p>
<section id="generative-models" class="level3">
<h3 class="anchored" data-anchor-id="generative-models">Generative Models</h3>
<ul>
<li><strong>Approach</strong>: Learn the joint probability distribution <span class="math inline">\(P(X, Y)\)</span> and use it to calculate the conditional probability <span class="math inline">\(P(Y|X)\)</span> for prediction.</li>
<li><strong>Goal</strong>: To model how data is generated by estimating the underlying probability distribution.</li>
<li><strong>Use</strong>: Common in supervised learning, especially when predicting class probabilities is important.</li>
<li><strong>Examples</strong>: Naive Bayes, Linear Discriminant Analysis, Quadratic Discriminant Analysis.</li>
</ul>
</section>
<section id="discriminative-models" class="level3">
<h3 class="anchored" data-anchor-id="discriminative-models">Discriminative Models</h3>
<ul>
<li><strong>Approach</strong>: Directly learn the conditional probability <span class="math inline">\(P(Y|X)\)</span> or decision boundary between classes without assuming anything about the joint distribution.</li>
<li><strong>Goal</strong>: To find a division in the feature space that separates classes.</li>
<li><strong>Use</strong>: Typically used in supervised learning to classify data into labeled categories.</li>
<li><strong>Examples</strong>: Logistic Regression, Support Vector Machines, Decision Trees.</li>
</ul>
<p>Understanding the distinctions between these paradigms and model types is crucial for selecting the appropriate approach for a given machine learning task.</p>
</section>
</section>
</section>
<section id="naive-bayes-as-a-generative-model" class="level1">
<h1>Naive Bayes as a Generative Model</h1>
<ul>
<li><p><strong>Naive Bayes</strong> is a fundamental example of a generative model.</p></li>
<li><p>It makes strong independence assumptions between features given the class label.</p></li>
<li><p>Uses Bayes’ Theorem to estimate the probability of each class given the feature vector <span class="math inline">\(X\)</span>.</p></li>
</ul>
<p><span class="math display">\[ P(C_k|X) = \frac{P(X|C_k)P(C_k)}{P(X)} \]</span></p>
<ul>
<li><strong>Strengths</strong>: Simplicity, efficiency, and effectiveness in high-dimensional spaces.</li>
</ul>
<section id="why-generative" class="level2">
<h2 class="anchored" data-anchor-id="why-generative">Why Generative?</h2>
<ul>
<li>By learning the distribution of each class <span class="math inline">\(P(X|C_k)\)</span> and the prior <span class="math inline">\(P(C_k)\)</span>, Naive Bayes models the generation process of the data.</li>
<li>This allows not only for classification but also for generating new data samples based on the learned distributions.</li>
</ul>
</section>
<section id="the-role-of-naive-bayes-in-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="the-role-of-naive-bayes-in-machine-learning">The Role of Naive Bayes in Machine Learning</h2>
<ul>
<li>Naive Bayes exemplifies the power and simplicity of generative models.</li>
<li>Provides a foundation for understanding more complex generative approaches.</li>
<li>Remains a go-to method for many classification tasks due to its interpretability and efficiency.</li>
</ul>
#
<center>
Naive Bayes Classifiers
</center>
</section>
<section id="overview-of-naive-bayes-classifiers" class="level2">
<h2 class="anchored" data-anchor-id="overview-of-naive-bayes-classifiers">Overview of Naive Bayes Classifiers</h2>
<p>Naive Bayes classifiers vary mainly by the distribution they assume for the feature data.</p>
<section id="gaussian-naive-bayes" class="level4">
<h4 class="anchored" data-anchor-id="gaussian-naive-bayes">Gaussian Naive Bayes</h4>
<ul>
<li>Used for features with a normal distribution.</li>
<li>Suitable for continuous data.</li>
</ul>
</section>
<section id="multinomial-naive-bayes" class="level4">
<h4 class="anchored" data-anchor-id="multinomial-naive-bayes">Multinomial Naive Bayes</h4>
<ul>
<li>Used for discrete data.</li>
<li>Ideal for features that represent counts (e.g., word counts in text classification).</li>
</ul>
</section>
<section id="bernoulli-naive-bayes" class="level4">
<h4 class="anchored" data-anchor-id="bernoulli-naive-bayes">Bernoulli Naive Bayes</h4>
<ul>
<li>Used for binary/boolean features.</li>
<li>Appropriate when features are independent and follow a binomial distribution.</li>
</ul>
</section>
<section id="also" class="level4">
<h4 class="anchored" data-anchor-id="also">Also:</h4>
<ul>
<li><strong>Complement Naive Bayes</strong>: A version of Multinomial Naive Bayes that is particularly suited for imbalanced data sets.</li>
<li><strong>Categorical Naive Bayes</strong>: Assumes that each feature has its own categorical distribution.</li>
</ul>
<p>Each variant is best suited to different types of data and it’s important to choose based on the nature of your features.</p>
</section>
</section>
</section>
<section id="gaussian-naive-bayes-1" class="level1">
<h1>Gaussian Naive Bayes</h1>
<ul>
<li><strong>Assumption</strong>: The features <span class="math inline">\(x_i\)</span> are assumed to be normally distributed (Gaussian) for each class <span class="math inline">\(C_k\)</span>.</li>
<li><strong>Applicability</strong>: Ideal for datasets where features are continuous and can be approximated by a Gaussian distribution.</li>
<li><strong><code>Python</code></strong>: <code>GaussianNB</code> in the <code>scikit-learn</code> package implements the Gaussian Naive Bayes algorithm for classification.</li>
</ul>
<section id="formula" class="level3">
<h3 class="anchored" data-anchor-id="formula">Formula:</h3>
<p><span class="math display">\[ P(x_i | C_k) = \frac{1}{\sqrt{2\pi\sigma_{k}^{2}}} \exp\left(-\frac{(x_i - \mu_{k})^2}{2\sigma_{k}^{2}}\right) \]</span></p>
<ul>
<li>Where <span class="math inline">\(\mu_{k}\)</span> and <span class="math inline">\(\sigma_{k}^{2}\)</span> are the mean and variance of feature <span class="math inline">\(x_i\)</span> for class <span class="math inline">\(C_k\)</span>. They are estimated using <a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation#:~:text=In%20statistics%2C%20maximum%20likelihood%20estimation,observed%20data%20is%20most%20probable.">maximum likelihood</a>.</li>
</ul>
</section>
</section>
<section id="multinomial-naive-bayes-1" class="level1">
<h1>Multinomial Naive Bayes</h1>
<ul>
<li><strong>Assumption</strong>: The features <span class="math inline">\(x_i\)</span> represent the frequencies with which certain events have been generated by a multinomial distribution.</li>
<li><strong>Applicability</strong>: Suited for count data, such as the frequency of words in text documents.</li>
<li><strong><code>Python</code></strong>: <code>MultinomialNB</code> in the <code>scikit-learn</code> package implements the naive Bayes algorithm for multinomially. The distribution is parametrized by vectors $ <em>{C_k} = (</em>{C_k1},,<em>{C_kn}) $ for each class $ C_k $, where $ n $ is the number of features and $ </em>{C_ki} $ is the probability $ P(x_i C_k) $ of feature $ i $ appearing in a sample belonging to class $ C_k $.</li>
</ul>
<p>The parameters $ _{C_k} $ is estimated by a smoothed version of maximum likelihood, i.e.&nbsp;relative frequency counting:</p>
<p><span class="math display">\[
\hat{\theta}_{C_ki} = \frac{ N_{C_ki} + \alpha}{N_{C_k} + \alpha n}
\]</span></p>
<p>where $ N_{C_ki} = <em>{x T} x_i $ is the number of times feature $ i $ appears in a sample of class $ C_k $ in the training set $ T $, and $ N</em>{C_k} = <em>{i=1}^{n} N</em>{C_ki} $ is the total count of all features for class $ C_k $.</p>
<p>If a given class and feature value never occur together in the training data, then the frequency-based probability estimate will be zero, because the probability estimate is directly proportional to the number of occurrences of a feature’s value. The smoothing priors $ $ accounts for features not present in the learning samples (<em>pseudocount</em>) and prevents zero probabilities in further computations. Setting $ = 1 $ is called <a href="https://en.wikipedia.org/wiki/Additive_smoothing">Laplace smoothing</a>, while $ &lt; 1 $ is called <a href="https://en.wikipedia.org/wiki/Additive_smoothing">Lidstone smoothing</a>.</p>
</section>
<section id="bernoulli-naive-bayes-1" class="level1">
<h1>Bernoulli Naive Bayes</h1>
<ul>
<li><p><strong>Assumption</strong>: The features <span class="math inline">\(x_i\)</span> are binary (Boolean) variables indicating the presence or absence of a feature.</p></li>
<li><p><strong>Applicability</strong>: Effective for datasets where features are binary, such as text classification where a word’s presence or absence is a feature.</p></li>
<li><p><strong><code>Python</code></strong>: <code>BernoulliNB</code> in the <code>scikit-learn</code> package implements the naive Bayes training and classification algorithms for data that is distributed according to multivariate Bernoulli distributions; i.e., there may be multiple features but each one is assumed to be a binary-valued (Bernoulli, boolean) variable. Therefore, this class requires samples to be represented as binary-valued feature vectors; if handed any other kind of data, a <code>BernoulliNB</code> instance may binarize its input (depending on the <code>binarize</code> parameter).</p></li>
</ul>
<p>The decision rule for Bernoulli naive Bayes is based on</p>
<p><span class="math display">\[
P(x_i \mid C_k) = P(x_i = 1 \mid C_k) x_i + (1 - P(x_i = 1 \mid C_k)) (1 - x_i)
\]</span></p>
<p>which differs from multinomial NB’s rule in that it explicitly penalizes the non-occurrence of a feature $ i $ that is an indicator for class $ y $, where the multinomial variant would simply ignore a non-occurring feature.</p>
<section id="choosing-the-right-naive-bayes-classifier" class="level2">
<h2 class="anchored" data-anchor-id="choosing-the-right-naive-bayes-classifier">Choosing the Right Naive Bayes Classifier</h2>
<p>Different Naive Bayes classifiers are suited to different types of data distributions.</p>
<section id="selection-strategy" class="level3">
<h3 class="anchored" data-anchor-id="selection-strategy">Selection Strategy</h3>
<ol type="1">
<li><p><strong>Analyze Features</strong>: Understand the distribution of your data (plot your data!).</p></li>
<li><p><strong>Preprocess</strong>: Tailor preprocessing to fit the model’s assumptions (e.g.&nbsp;log transformations).</p></li>
<li><p><strong>Domain Knowledge</strong>: Let insights from the domain guide your choice.</p></li>
<li><p><strong>Model Comparison</strong>: Apply different models and evaluate their performance with cross-validation.</p></li>
<li><p><strong>Hyperparameter Tuning</strong>: For Naive Bayes models, particularly Multinomial and Bernoulli, the <code>alpha</code> parameter is crucial. Correctly tuning the <code>alpha</code> parameter is a form of regularization that enhances the model’s accuracy and robustness, especially important for sparse or imbalanced datasets.</p></li>
</ol>
<p>The best classifier aligns with the statistical properties of your data and performs best empirically.</p>
</section>
</section>
</section>
<section id="measuring-performance" class="level1">
<h1>Measuring Performance</h1>
<p><strong>Confusion Matrix</strong>: it is a powerful tool for measuring the performance of a classification model. It provides insights beyond overall accuracy, allowing for a detailed analysis of the model’s effectiveness.</p>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th><strong>Predicted: 0</strong></th>
<th><strong>Predicted: 1</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Actual: 0</strong></td>
<td>True Negative</td>
<td>False Positive</td>
</tr>
<tr class="even">
<td><strong>Actual: 1</strong></td>
<td>False Negative</td>
<td>True Positive</td>
</tr>
</tbody>
</table>
<ol type="1">
<li><strong>Accuracy:</strong> <span class="math display">\[\dfrac{\text{correct predictions}}{\text{total observations}} \ = \ \dfrac{tp + tn}{tp + tn + fp + fn}\]</span></li>
</ol>
<ul>
<li>Overall effectiveness of the model.</li>
<li>High accuracy: lots of correct predictions!</li>
</ul>
<section id="measuring-performance-1" class="level3">
<h3 class="anchored" data-anchor-id="measuring-performance-1">Measuring Performance</h3>
<p><strong>Confusion Matrix</strong>:</p>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th><strong>Predicted: 0</strong></th>
<th><strong>Predicted: 1</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Actual: 0</strong></td>
<td>True Negative</td>
<td>False Positive</td>
</tr>
<tr class="even">
<td><strong>Actual: 1</strong></td>
<td>False Negative</td>
<td>True Positive</td>
</tr>
</tbody>
</table>
<ol start="2" type="1">
<li><strong>Precision:</strong> <span class="math display">\[\dfrac{\text{true positives}}{\text{total predicted positive}} \ = \ \dfrac{tp}{tp + fp}\]</span></li>
</ol>
<ul>
<li>Accuracy of positive predictions.</li>
<li>High precision: low false-positive rates.</li>
</ul>
</section>
<section id="measuring-performance-2" class="level3">
<h3 class="anchored" data-anchor-id="measuring-performance-2">Measuring Performance</h3>
<p><strong>Confusion Matrix</strong>:</p>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th><strong>Predicted: 0</strong></th>
<th><strong>Predicted: 1</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Actual: 0</strong></td>
<td>True Negative</td>
<td>False Positive</td>
</tr>
<tr class="even">
<td><strong>Actual: 1</strong></td>
<td>False Negative</td>
<td>True Positive</td>
</tr>
</tbody>
</table>
<ol start="3" type="1">
<li><strong>Recall:</strong> <span class="math display">\[\dfrac{\text{true positives}}{\text{total actual positive}} \ = \ \dfrac{tp}{tp + fn}\]</span></li>
</ol>
<ul>
<li>Fraction of positives correctly identified.</li>
<li>High recall: low false-negative rates.</li>
</ul>
</section>
<section id="measuring-performance-3" class="level3">
<h3 class="anchored" data-anchor-id="measuring-performance-3">Measuring Performance</h3>
<ol start="4" type="1">
<li><strong>F1-Score</strong>:</li>
</ol>
<p><span class="math display">\[ \text{F1} \ = \ 2 \times \dfrac{\text{precision} \times \text{recall}}{\text{precision} + \text{recall}} \]</span></p>
<ul>
<li>Harmonic mean of precision and recall.</li>
<li>A higher F1 score indicates a better balance between precision and recall. For example, in a medical diagnosis scenario, you would want a model that neither predicts too many false negatives (missing out on true cases) nor too many false positives (causing unnecessary alarm).</li>
</ul>
</section>
<section id="understanding-model-performance" class="level2">
<h2 class="anchored" data-anchor-id="understanding-model-performance">Understanding Model Performance</h2>
<p><br></p>
<ul>
<li><p><strong>Imbalanced Classes</strong>: Precision, Recall, and F1 score are crucial in the presence of imbalanced classes.</p></li>
<li><p><strong>Model Objective</strong>: Prioritize metrics based on the application needs, e.g., Recall over Precision in medical diagnostics.</p></li>
</ul>
<p>The <strong>confusion matrix</strong> offers a comprehensive way to evaluate and improve classification models by providing insights into their specific strengths and weaknesses.</p>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th><strong>Predicted: 0</strong></th>
<th><strong>Predicted: 1</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Actual: 0</strong></td>
<td>True Negative</td>
<td>False Positive</td>
</tr>
<tr class="even">
<td><strong>Actual: 1</strong></td>
<td>False Negative</td>
<td>True Positive</td>
</tr>
</tbody>
</table>
#
<center>
Let’s Practice!
</center>
</section>
<section id="practice-gaussian-naive-bayes" class="level2">
<h2 class="anchored" data-anchor-id="practice-gaussian-naive-bayes">Practice: Gaussian Naive Bayes</h2>
</section>
<section id="pima-indians-diabetes-database-overview" class="level2">
<h2 class="anchored" data-anchor-id="pima-indians-diabetes-database-overview">Pima Indians Diabetes Database Overview</h2>
<section id="context" class="level3">
<h3 class="anchored" data-anchor-id="context">Context</h3>
<ul>
<li>This dataset (<a href="https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database/data">Kaggle Dataset Link</a>) originates from the <strong>National Institute of Diabetes and Digestive and Kidney Diseases</strong>.</li>
<li>The aim is to predict whether a patient has diabetes based on diagnostic measurements.</li>
<li>All patients are females of at least 21 years old of <strong>Pima Indian heritage</strong>, selected under specific constraints for this study.</li>
</ul>
</section>
<section id="content" class="level3">
<h3 class="anchored" data-anchor-id="content">Content</h3>
<p>The dataset features several medical predictor variables alongside one target variable, <code>Outcome</code>. Predictor variables include:</p>
<ul>
<li>Number of pregnancies</li>
<li>BMI (Body Mass Index)</li>
<li>Insulin level</li>
<li>Age</li>
<li>…among others.</li>
</ul>
<p>These variables assist in diagnostically predicting diabetes presence.</p>
</section>
<section id="step-0-import-libraries-and-dataset" class="level3">
<h3 class="anchored" data-anchor-id="step-0-import-libraries-and-dataset">Step 0: Import libraries and Dataset</h3>
<div id="67732bf8" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="300">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Importing libraries</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pandas.plotting <span class="im">import</span> scatter_matrix</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> MinMaxScaler</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, cross_val_score</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Importing dataset</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'diabetes.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-1-descriptive-statistics" class="level3">
<h3 class="anchored" data-anchor-id="step-1-descriptive-statistics">Step 1: Descriptive Statistics</h3>
<div id="4c5ee493" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="301">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Preview data</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="301">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Pregnancies</th>
<th data-quarto-table-cell-role="th">Glucose</th>
<th data-quarto-table-cell-role="th">BloodPressure</th>
<th data-quarto-table-cell-role="th">SkinThickness</th>
<th data-quarto-table-cell-role="th">Insulin</th>
<th data-quarto-table-cell-role="th">BMI</th>
<th data-quarto-table-cell-role="th">DiabetesPedigreeFunction</th>
<th data-quarto-table-cell-role="th">Age</th>
<th data-quarto-table-cell-role="th">Outcome</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>6</td>
<td>148</td>
<td>72</td>
<td>35</td>
<td>0</td>
<td>33.6</td>
<td>0.627</td>
<td>50</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>85</td>
<td>66</td>
<td>29</td>
<td>0</td>
<td>26.6</td>
<td>0.351</td>
<td>31</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>8</td>
<td>183</td>
<td>64</td>
<td>0</td>
<td>0</td>
<td>23.3</td>
<td>0.672</td>
<td>32</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>89</td>
<td>66</td>
<td>23</td>
<td>94</td>
<td>28.1</td>
<td>0.167</td>
<td>21</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0</td>
<td>137</td>
<td>40</td>
<td>35</td>
<td>168</td>
<td>43.1</td>
<td>2.288</td>
<td>33</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="3dd32c17" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="302">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Dataset dimensions - (rows, columns)</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>df.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="302">
<pre><code>(768, 9)</code></pre>
</div>
</div>
<div id="9eff8d10" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="303">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Features data-type</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>df.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 768 entries, 0 to 767
Data columns (total 9 columns):
 #   Column                    Non-Null Count  Dtype  
---  ------                    --------------  -----  
 0   Pregnancies               768 non-null    int64  
 1   Glucose                   768 non-null    int64  
 2   BloodPressure             768 non-null    int64  
 3   SkinThickness             768 non-null    int64  
 4   Insulin                   768 non-null    int64  
 5   BMI                       768 non-null    float64
 6   DiabetesPedigreeFunction  768 non-null    float64
 7   Age                       768 non-null    int64  
 8   Outcome                   768 non-null    int64  
dtypes: float64(2), int64(7)
memory usage: 54.1 KB</code></pre>
</div>
</div>
<div id="a80e8a8c" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="304">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Statistical summary</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>df.describe().T</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="304">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">count</th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">std</th>
<th data-quarto-table-cell-role="th">min</th>
<th data-quarto-table-cell-role="th">25%</th>
<th data-quarto-table-cell-role="th">50%</th>
<th data-quarto-table-cell-role="th">75%</th>
<th data-quarto-table-cell-role="th">max</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Pregnancies</td>
<td>768.0</td>
<td>3.845052</td>
<td>3.369578</td>
<td>0.000</td>
<td>1.00000</td>
<td>3.0000</td>
<td>6.00000</td>
<td>17.00</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Glucose</td>
<td>768.0</td>
<td>120.894531</td>
<td>31.972618</td>
<td>0.000</td>
<td>99.00000</td>
<td>117.0000</td>
<td>140.25000</td>
<td>199.00</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">BloodPressure</td>
<td>768.0</td>
<td>69.105469</td>
<td>19.355807</td>
<td>0.000</td>
<td>62.00000</td>
<td>72.0000</td>
<td>80.00000</td>
<td>122.00</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">SkinThickness</td>
<td>768.0</td>
<td>20.536458</td>
<td>15.952218</td>
<td>0.000</td>
<td>0.00000</td>
<td>23.0000</td>
<td>32.00000</td>
<td>99.00</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Insulin</td>
<td>768.0</td>
<td>79.799479</td>
<td>115.244002</td>
<td>0.000</td>
<td>0.00000</td>
<td>30.5000</td>
<td>127.25000</td>
<td>846.00</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">BMI</td>
<td>768.0</td>
<td>31.992578</td>
<td>7.884160</td>
<td>0.000</td>
<td>27.30000</td>
<td>32.0000</td>
<td>36.60000</td>
<td>67.10</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">DiabetesPedigreeFunction</td>
<td>768.0</td>
<td>0.471876</td>
<td>0.331329</td>
<td>0.078</td>
<td>0.24375</td>
<td>0.3725</td>
<td>0.62625</td>
<td>2.42</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Age</td>
<td>768.0</td>
<td>33.240885</td>
<td>11.760232</td>
<td>21.000</td>
<td>24.00000</td>
<td>29.0000</td>
<td>41.00000</td>
<td>81.00</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Outcome</td>
<td>768.0</td>
<td>0.348958</td>
<td>0.476951</td>
<td>0.000</td>
<td>0.00000</td>
<td>0.0000</td>
<td>1.00000</td>
<td>1.00</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="625ee924" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="305">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Count of null values</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>df.isnull().<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="305">
<pre><code>Pregnancies                 0
Glucose                     0
BloodPressure               0
SkinThickness               0
Insulin                     0
BMI                         0
DiabetesPedigreeFunction    0
Age                         0
Outcome                     0
dtype: int64</code></pre>
</div>
</div>
</section>
<section id="observations" class="level3">
<h3 class="anchored" data-anchor-id="observations">Observations:</h3>
<ol type="1">
<li>There are a total of 768 records and 9 features in the dataset.</li>
<li>Each feature can be either of integer or float dataype.</li>
<li>Some features like Glucose, Blood pressure, Insulin, BMI have zero values which represent missing data.</li>
<li>There are zero NaN values in the dataset.</li>
<li>In the outcome column, 1 represents diabetes positive and 0 represents diabetes negative.</li>
</ol>
<div id="d26eba96" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="306">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Outcome countplot</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>sns.countplot(x <span class="op">=</span> <span class="st">'Outcome'</span>,data <span class="op">=</span> dataset)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="naive_bayes_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="97d34d43" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="307">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Histogram of each feature</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>col <span class="op">=</span> df.columns[:<span class="dv">8</span>]</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>plt.subplots(figsize <span class="op">=</span> (<span class="dv">20</span>, <span class="dv">15</span>))</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>length <span class="op">=</span> <span class="bu">len</span>(col)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, j <span class="kw">in</span> itertools.zip_longest(col, <span class="bu">range</span>(length)):</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    plt.subplot((length<span class="op">//</span><span class="dv">2</span>), <span class="dv">3</span>, j <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    plt.subplots_adjust(wspace <span class="op">=</span> <span class="fl">0.1</span>,hspace <span class="op">=</span> <span class="fl">0.5</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    df[i].hist(bins <span class="op">=</span> <span class="dv">20</span>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    plt.title(i)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="naive_bayes_files/figure-html/cell-9-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="6494a0b1" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="309">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot matrix </span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>scatter_matrix(df, figsize <span class="op">=</span> (<span class="dv">20</span>, <span class="dv">20</span>))<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="naive_bayes_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="3694147e" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="310">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pairplot </span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>sns.pairplot(data <span class="op">=</span> df, hue <span class="op">=</span> <span class="st">'Outcome'</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="naive_bayes_files/figure-html/cell-11-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="00f05180" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="311">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Heatmap</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>sns.heatmap(df.corr(), annot <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="naive_bayes_files/figure-html/cell-12-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="observations-1" class="level3">
<h3 class="anchored" data-anchor-id="observations-1">Observations:</h3>
<ol type="1">
<li><p>The countplot tells us that the dataset is imbalanced, as number of patients who don’t have diabetes is more than those who do.</p></li>
<li><p>From the correaltion heatmap, we can see that there is a high correlation between Outcome and [Glucose,BMI,Age,Insulin].</p></li>
</ol>
</section>
<section id="step-2-data-preprocessing" class="level3">
<h3 class="anchored" data-anchor-id="step-2-data-preprocessing">Step 2: Data Preprocessing</h3>
<div id="8da32c6a" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="312">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>df_new <span class="op">=</span> df</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co"># list(df_new)</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Preview data</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>df_new.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="312">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Pregnancies</th>
<th data-quarto-table-cell-role="th">Glucose</th>
<th data-quarto-table-cell-role="th">BloodPressure</th>
<th data-quarto-table-cell-role="th">SkinThickness</th>
<th data-quarto-table-cell-role="th">Insulin</th>
<th data-quarto-table-cell-role="th">BMI</th>
<th data-quarto-table-cell-role="th">DiabetesPedigreeFunction</th>
<th data-quarto-table-cell-role="th">Age</th>
<th data-quarto-table-cell-role="th">Outcome</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>6</td>
<td>148</td>
<td>72</td>
<td>35</td>
<td>0</td>
<td>33.6</td>
<td>0.627</td>
<td>50</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>85</td>
<td>66</td>
<td>29</td>
<td>0</td>
<td>26.6</td>
<td>0.351</td>
<td>31</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>8</td>
<td>183</td>
<td>64</td>
<td>0</td>
<td>0</td>
<td>23.3</td>
<td>0.672</td>
<td>32</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>89</td>
<td>66</td>
<td>23</td>
<td>94</td>
<td>28.1</td>
<td>0.167</td>
<td>21</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0</td>
<td>137</td>
<td>40</td>
<td>35</td>
<td>168</td>
<td>43.1</td>
<td>2.288</td>
<td>33</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="b71363cb" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="313">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># checking zero values</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co"># np.where(df_new['Glucose'] == 0)[0].shape</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># np.where(df_new['BloodPressure'] == 0)[0].shape</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># np.where(df_new['SkinThickness'] == 0)[0].shape</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>np.where(df_new[<span class="st">'Insulin'</span>] <span class="op">==</span> <span class="dv">0</span>)[<span class="dv">0</span>].shape</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co"># np.where(df_new['BMI'] == 0)[0].shape</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># np.where(df_new['DiabetesPedigreeFunction'] == 0)[0].shape</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co"># np.where(df_new['Age'] == 0)[0].shape</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="313">
<pre><code>(374,)</code></pre>
</div>
</div>
<div id="f60cdd3c" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="314">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Replacing zero values with NaN</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>df_new[[<span class="st">'Glucose'</span>,</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a> <span class="st">'BloodPressure'</span>,</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a> <span class="st">'SkinThickness'</span>,</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a> <span class="st">'Insulin'</span>,</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a> <span class="st">'BMI'</span>,</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a> <span class="st">'DiabetesPedigreeFunction'</span>,</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a> <span class="st">'Age'</span>]] <span class="op">=</span> df_new[[<span class="st">'Glucose'</span>,</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a> <span class="st">'BloodPressure'</span>,</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a> <span class="st">'SkinThickness'</span>,</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a> <span class="st">'Insulin'</span>,</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a> <span class="st">'BMI'</span>,</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a> <span class="st">'DiabetesPedigreeFunction'</span>,</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a> <span class="st">'Age'</span>]].replace(<span class="dv">0</span>, np.NaN) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="1081c2e4" class="cell" data-scrolled="true" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="315">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Count of NaN</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>df_new.isnull().<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="315">
<pre><code>Pregnancies                   0
Glucose                       5
BloodPressure                35
SkinThickness               227
Insulin                     374
BMI                          11
DiabetesPedigreeFunction      0
Age                           0
Outcome                       0
dtype: int64</code></pre>
</div>
</div>
<div id="83d3cb72" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="316">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Removing Features with too many zeros NaNs</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>df_new <span class="op">=</span> df_new.drop([<span class="st">'SkinThickness'</span>, <span class="st">'Insulin'</span>], axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Removing Observations with NaNs</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>df_new <span class="op">=</span> df_new.dropna(subset<span class="op">=</span>[<span class="st">'Glucose'</span>])</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>df_new <span class="op">=</span> df_new.dropna(subset<span class="op">=</span>[<span class="st">'BloodPressure'</span>])</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>df_new <span class="op">=</span> df_new.dropna(subset<span class="op">=</span>[<span class="st">'BMI'</span>])</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co">#dataset_new = dataset_new[dataset_new['Glucose'] != 0]</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="co">#dataset_new = dataset_new[dataset_new['BloodPressure'] != 0]</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="co">#dataset_new = dataset_new[dataset_new['BMI'] != 0]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="fdddbd1a" class="cell" data-scrolled="true" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="317">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Statistical summary</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>df_new.describe().T</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="317">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">count</th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">std</th>
<th data-quarto-table-cell-role="th">min</th>
<th data-quarto-table-cell-role="th">25%</th>
<th data-quarto-table-cell-role="th">50%</th>
<th data-quarto-table-cell-role="th">75%</th>
<th data-quarto-table-cell-role="th">max</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Pregnancies</td>
<td>724.0</td>
<td>3.866022</td>
<td>3.362803</td>
<td>0.000</td>
<td>1.000</td>
<td>3.000</td>
<td>6.0000</td>
<td>17.00</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Glucose</td>
<td>724.0</td>
<td>121.882597</td>
<td>30.750030</td>
<td>44.000</td>
<td>99.750</td>
<td>117.000</td>
<td>142.0000</td>
<td>199.00</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">BloodPressure</td>
<td>724.0</td>
<td>72.400552</td>
<td>12.379870</td>
<td>24.000</td>
<td>64.000</td>
<td>72.000</td>
<td>80.0000</td>
<td>122.00</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">BMI</td>
<td>724.0</td>
<td>32.467127</td>
<td>6.888941</td>
<td>18.200</td>
<td>27.500</td>
<td>32.400</td>
<td>36.6000</td>
<td>67.10</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">DiabetesPedigreeFunction</td>
<td>724.0</td>
<td>0.474765</td>
<td>0.332315</td>
<td>0.078</td>
<td>0.245</td>
<td>0.379</td>
<td>0.6275</td>
<td>2.42</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Age</td>
<td>724.0</td>
<td>33.350829</td>
<td>11.765393</td>
<td>21.000</td>
<td>24.000</td>
<td>29.000</td>
<td>41.0000</td>
<td>81.00</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Outcome</td>
<td>724.0</td>
<td>0.343923</td>
<td>0.475344</td>
<td>0.000</td>
<td>0.000</td>
<td>0.000</td>
<td>1.0000</td>
<td>1.00</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="74ee4e8c" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="318">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># log transformation</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>df_new[<span class="st">'LogPregnancies'</span>] <span class="op">=</span> np.log1p(df_new[<span class="st">'Pregnancies'</span>])</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>df_new[<span class="st">'LogDiabetesPedigreeFunction'</span>] <span class="op">=</span> np.log1p(df_new[<span class="st">'DiabetesPedigreeFunction'</span>])</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>df_new[<span class="st">'LogAge'</span>] <span class="op">=</span> np.log1p(df_new[<span class="st">'Age'</span>])</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Statistical summary</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>df_new.describe().T</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="318">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">count</th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">std</th>
<th data-quarto-table-cell-role="th">min</th>
<th data-quarto-table-cell-role="th">25%</th>
<th data-quarto-table-cell-role="th">50%</th>
<th data-quarto-table-cell-role="th">75%</th>
<th data-quarto-table-cell-role="th">max</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Pregnancies</td>
<td>724.0</td>
<td>3.866022</td>
<td>3.362803</td>
<td>0.000000</td>
<td>1.000000</td>
<td>3.000000</td>
<td>6.000000</td>
<td>17.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Glucose</td>
<td>724.0</td>
<td>121.882597</td>
<td>30.750030</td>
<td>44.000000</td>
<td>99.750000</td>
<td>117.000000</td>
<td>142.000000</td>
<td>199.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">BloodPressure</td>
<td>724.0</td>
<td>72.400552</td>
<td>12.379870</td>
<td>24.000000</td>
<td>64.000000</td>
<td>72.000000</td>
<td>80.000000</td>
<td>122.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">BMI</td>
<td>724.0</td>
<td>32.467127</td>
<td>6.888941</td>
<td>18.200000</td>
<td>27.500000</td>
<td>32.400000</td>
<td>36.600000</td>
<td>67.100000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">DiabetesPedigreeFunction</td>
<td>724.0</td>
<td>0.474765</td>
<td>0.332315</td>
<td>0.078000</td>
<td>0.245000</td>
<td>0.379000</td>
<td>0.627500</td>
<td>2.420000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Age</td>
<td>724.0</td>
<td>33.350829</td>
<td>11.765393</td>
<td>21.000000</td>
<td>24.000000</td>
<td>29.000000</td>
<td>41.000000</td>
<td>81.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Outcome</td>
<td>724.0</td>
<td>0.343923</td>
<td>0.475344</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">LogPregnancies</td>
<td>724.0</td>
<td>1.319311</td>
<td>0.762929</td>
<td>0.000000</td>
<td>0.693147</td>
<td>1.386294</td>
<td>1.945910</td>
<td>2.890372</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">LogDiabetesPedigreeFunction</td>
<td>724.0</td>
<td>0.367237</td>
<td>0.198718</td>
<td>0.075107</td>
<td>0.219136</td>
<td>0.321358</td>
<td>0.487045</td>
<td>1.229641</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">LogAge</td>
<td>724.0</td>
<td>3.484730</td>
<td>0.313971</td>
<td>3.091042</td>
<td>3.218876</td>
<td>3.401197</td>
<td>3.737670</td>
<td>4.406719</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="7b5a5324" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="322">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Histogram of each feature</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>col <span class="op">=</span> df_new.columns[:<span class="dv">10</span>]</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>plt.subplots(figsize <span class="op">=</span> (<span class="dv">20</span>, <span class="dv">15</span>))</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>length <span class="op">=</span> <span class="bu">len</span>(col)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, j <span class="kw">in</span> itertools.zip_longest(col, <span class="bu">range</span>(length)):</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    plt.subplot((length<span class="op">//</span><span class="dv">2</span>), <span class="dv">3</span>, j <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>    plt.subplots_adjust(wspace <span class="op">=</span> <span class="fl">0.1</span>,hspace <span class="op">=</span> <span class="fl">0.5</span>)</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>    df_new[i].hist(bins <span class="op">=</span> <span class="dv">20</span>)</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    plt.title(i)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="naive_bayes_files/figure-html/cell-20-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="440008c6" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="323">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Selecting features </span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> [</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'LogPregnancies'</span>,</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Glucose'</span>,</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'BloodPressure'</span>,</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'BMI'</span>,</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'LogDiabetesPedigreeFunction'</span>,</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'LogAge'</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting X and Y</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>df_train, df_test <span class="op">=</span> train_test_split(df_new, test_size <span class="op">=</span> <span class="fl">0.20</span>, random_state <span class="op">=</span> <span class="dv">42</span>, stratify <span class="op">=</span> df_new[<span class="st">'Outcome'</span>] )</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> df_train[features]</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>Y_train <span class="op">=</span> df_train[<span class="st">'Outcome'</span>]</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> df_test[features]</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>Y_test <span class="op">=</span> df_test[<span class="st">'Outcome'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="bad8c802" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="324">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Checking dimensions</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"X_train shape:"</span>, X_train.shape)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"X_test shape:"</span>, X_test.shape)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Y_train shape:"</span>, Y_train.shape)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Y_test shape:"</span>, Y_test.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>X_train shape: (579, 6)
X_test shape: (145, 6)
Y_train shape: (579,)
Y_test shape: (145,)</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="step-3-data-modelling" class="level1">
<h1>Step 3: Data Modelling</h1>
<div id="94ecfda4" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="325">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Naive Bayes Algorithm</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>nb <span class="op">=</span> GaussianNB()</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>nb.fit(X_train, Y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="325">
<style>#sk-container-id-9 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-9 {
  color: var(--sklearn-color-text);
}

#sk-container-id-9 pre {
  padding: 0;
}

#sk-container-id-9 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-9 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-9 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-9 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-9 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-9 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-9 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-9 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-9 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-9 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-9 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-9 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-9 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-9 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-9 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-9 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-9 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-9 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-9 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-9 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-9 div.sk-label label.sk-toggleable__label,
#sk-container-id-9 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-9 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-9 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-9 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-9 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-9 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-9 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-9 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-9 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-9 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-9 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-9 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style><div id="sk-container-id-9" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-11" type="checkbox" checked=""><label for="sk-estimator-id-11" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GaussianNB<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.4/modules/generated/sklearn.naive_bayes.GaussianNB.html">?<span>Documentation for GaussianNB</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GaussianNB()</pre></div> </div></div></div></div>
</div>
</div>
<div id="75e0afba" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="326">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Making predictions on test dataset</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>Y_pred_nb <span class="op">=</span> nb.predict(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-4-model-evaluation" class="level1">
<h1>Step 4: Model Evaluation</h1>
<div id="5b9d4a02" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="327">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluating using accuracy_score metric</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>accuracy_nb <span class="op">=</span> accuracy_score(Y_test, Y_pred_nb)</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Accuracy on test set</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Naive Bayes: "</span> <span class="op">+</span> <span class="bu">str</span>(accuracy_nb <span class="op">*</span> <span class="dv">100</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Naive Bayes: 70.34482758620689</code></pre>
</div>
</div>
<div id="f8ad454c" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="328">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(Y_test, Y_pred_nb)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>cm</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="328">
<pre><code>array([[71, 24],
       [19, 31]])</code></pre>
</div>
</div>
<div id="60002e02" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="329">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Heatmap of Confusion matrix</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>sns.heatmap(pd.DataFrame(cm), annot<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="naive_bayes_files/figure-html/cell-27-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="d341f836" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="330">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Classification report</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(Y_test, Y_pred_nb))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0       0.79      0.75      0.77        95
           1       0.56      0.62      0.59        50

    accuracy                           0.70       145
   macro avg       0.68      0.68      0.68       145
weighted avg       0.71      0.70      0.71       145
</code></pre>
</div>
</div>
<div id="3db30139" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="335">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cross Validation</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df_new[features]</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_new[<span class="st">'Outcome'</span>]</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> cross_val_score(nb, X, y, scoring <span class="op">=</span> <span class="st">'accuracy'</span>)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Recall: If we consider that the cost of not classifying someone with diabetes is high, </span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="co"># that failing to identify a sick patient (a false negative) is more dangerous </span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co"># than incorrectly diagnosing a healthy patient as sick (a false positive).</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>result.mean(), result.std()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="335">
<pre><code>(0.7721264367816092, 0.023241424787067366)</code></pre>
</div>
</div>
</section>
<section id="practice-multinomial-naive-bayes" class="level1">
<h1>Practice: Multinomial Naive Bayes</h1>
<section id="practice-multinomial-naive-bayes-1" class="level2">
<h2 class="anchored" data-anchor-id="practice-multinomial-naive-bayes-1">Practice: Multinomial Naive Bayes</h2>
</section>
<section id="bbc-full-text-document-classification" class="level2">
<h2 class="anchored" data-anchor-id="bbc-full-text-document-classification">BBC Full Text Document Classification</h2>
<section id="context-1" class="level3">
<h3 class="anchored" data-anchor-id="context-1">Context</h3>
<ul>
<li>The original dataset (<a href="https://www.kaggle.com/datasets/dheemanthbhat/bbc-full-text-preprocessed">Kaggle Dataset Link</a>) consists of 2225 documents (as text files) from the BBC news website corresponding to news articles in five topical areas:
<ul>
<li>business</li>
<li>entertainment</li>
<li>politics</li>
<li>sport</li>
<li>tech</li>
</ul></li>
<li>The aim is to predict which topic does a news article belong to based on its content.</li>
</ul>
</section>
<section id="step-0-import-libraries-and-dataset-1" class="level3">
<h3 class="anchored" data-anchor-id="step-0-import-libraries-and-dataset-1">Step 0: Import Libraries and Dataset</h3>
<div id="0b1f216f" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="336">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer, TfidfVectorizer</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, cross_val_score</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> MultinomialNB</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, classification_report</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem <span class="im">import</span> PorterStemmer</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> word_tokenize</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Download necessary NLTK resources</span></span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'punkt'</span>)</span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'stopwords'</span>)</span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a><span class="co"># load data</span></span>
<span id="cb41-23"><a href="#cb41-23" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'bbc_text_cls.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package punkt to /Users/dcorde3/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package stopwords to
[nltk_data]     /Users/dcorde3/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!</code></pre>
</div>
</div>
<div id="e97500f8" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="337">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Preview data</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>df.head()</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="co"># len(df)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="337">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">labels</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Ad sales boost Time Warner profit\n\nQuarterly...</td>
<td>business</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Dollar gains on Greenspan speech\n\nThe dollar...</td>
<td>business</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Yukos unit buyer faces loan claim\n\nThe owner...</td>
<td>business</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>High fuel prices hit BA's profits\n\nBritish A...</td>
<td>business</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>Pernod takeover talk lifts Domecq\n\nShares in...</td>
<td>business</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
</section>
</section>
<section id="step-1-descriptive-statistics-1" class="level1">
<h1>Step 1: Descriptive Statistics</h1>
<div id="9680bbc6" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="338">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># let's check labels frequency</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>labels.hist(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="naive_bayes_files/figure-html/cell-32-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="step-2-data-preprocessing-1" class="level1">
<h1>Step 2: Data Preprocessing</h1>
<div id="e9e0f81d" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="339">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the preprocessing function</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess_text(text):</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handles the removal of stopwords and stemming</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Tokenize the text</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> word_tokenize(text)</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove punctuation and make lower case</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> [token.lower() <span class="cf">for</span> token <span class="kw">in</span> tokens <span class="cf">if</span> token.isalpha()]</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove stopwords</span></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>    stop_words <span class="op">=</span> <span class="bu">set</span>(stopwords.words(<span class="st">'english'</span>))</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> [token <span class="cf">for</span> token <span class="kw">in</span> tokens <span class="cf">if</span> token <span class="kw">not</span> <span class="kw">in</span> stop_words]</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Stem the words</span></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>    stemmer <span class="op">=</span> PorterStemmer()</span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> [stemmer.stem(token) <span class="cf">for</span> token <span class="kw">in</span> tokens]</span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">' '</span>.join(tokens)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="284615f4" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="340">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the preprocessing to each row</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'processed_text'</span>] <span class="op">=</span> df[<span class="st">'text'</span>].<span class="bu">apply</span>(preprocess_text)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="ccf96799" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="341">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="341">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">labels</th>
<th data-quarto-table-cell-role="th">processed_text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Ad sales boost Time Warner profit\n\nQuarterly...</td>
<td>business</td>
<td>ad sale boost time warner profit quarterli pro...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Dollar gains on Greenspan speech\n\nThe dollar...</td>
<td>business</td>
<td>dollar gain greenspan speech dollar hit highes...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Yukos unit buyer faces loan claim\n\nThe owner...</td>
<td>business</td>
<td>yuko unit buyer face loan claim owner embattl ...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>High fuel prices hit BA's profits\n\nBritish A...</td>
<td>business</td>
<td>high fuel price hit ba profit british airway b...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>Pernod takeover talk lifts Domecq\n\nShares in...</td>
<td>business</td>
<td>pernod takeov talk lift domecq share uk drink ...</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="c8de86d4" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="342">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into features and labels</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> df[<span class="st">'processed_text'</span>]</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> df[<span class="st">'labels'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="ed721a14" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="343">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into train and test sets</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>features_train, features_test, labels_train, labels_test <span class="op">=</span> train_test_split(features, labels, </span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>                                                                            test_size<span class="op">=</span><span class="fl">0.2</span>, </span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>                                                                            random_state<span class="op">=</span><span class="dv">123</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cbad4251" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="344">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a text processing and classification pipeline</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>pipeline <span class="op">=</span> make_pipeline(</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Bag of Words</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert the processed text into a matrix of token counts, </span></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># which is then used as input to the MultinomialNB classifier</span></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>    CountVectorizer(),</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>    MultinomialNB()</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-4-data-modeling" class="level1">
<h1>Step 4: Data Modeling</h1>
<div id="839b3cb9" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="345">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>pipeline.fit(inputs_train, labels_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="345">
<style>#sk-container-id-10 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-10 {
  color: var(--sklearn-color-text);
}

#sk-container-id-10 pre {
  padding: 0;
}

#sk-container-id-10 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-10 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-10 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-10 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-10 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-10 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-10 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-10 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-10 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-10 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-10 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-10 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-10 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-10 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-10 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-10 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-10 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-10 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-10 div.sk-label label.sk-toggleable__label,
#sk-container-id-10 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-10 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-10 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-10 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-10 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-10 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-10 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-10 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-10 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-10 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-10 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style><div id="sk-container-id-10" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[('countvectorizer', CountVectorizer()),
                ('multinomialnb', MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-12" type="checkbox"><label for="sk-estimator-id-12" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;Pipeline<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[('countvectorizer', CountVectorizer()),
                ('multinomialnb', MultinomialNB())])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-13" type="checkbox"><label for="sk-estimator-id-13" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;CountVectorizer<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">?<span>Documentation for CountVectorizer</span></a></label><div class="sk-toggleable__content fitted"><pre>CountVectorizer()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-14" type="checkbox"><label for="sk-estimator-id-14" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;MultinomialNB<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.4/modules/generated/sklearn.naive_bayes.MultinomialNB.html">?<span>Documentation for MultinomialNB</span></a></label><div class="sk-toggleable__content fitted"><pre>MultinomialNB()</pre></div> </div></div></div></div></div></div>
</div>
</div>
<div id="51eb6ee7" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="348">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on the test set</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>labels_pred <span class="op">=</span> pipeline.predict(features_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="aa75ae69" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 5: Model Evaluation</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="f3673325" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="349">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model using train-test split</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train-test split evaluation:"</span>)</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(labels_test, labels_pred))</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(labels_test, labels_pred)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Train-test split evaluation:
               precision    recall  f1-score   support

     business       0.96      0.94      0.95        86
entertainment       1.00      0.93      0.96        82
     politics       0.92      0.97      0.94        95
        sport       0.99      1.00      1.00       107
         tech       0.95      0.97      0.96        75

     accuracy                           0.96       445
    macro avg       0.96      0.96      0.96       445
 weighted avg       0.97      0.96      0.96       445

Accuracy: 0.9640449438202248</code></pre>
</div>
</div>
<div id="09f7017d" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="350">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model using cross-validation</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>cross_val_accuracy <span class="op">=</span> cross_val_score(pipeline, inputs_train, labels_train, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">'accuracy'</span>)</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Cross-validation evaluation:"</span>)</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Cross-validated accuracy: </span><span class="sc">{</span>np<span class="sc">.</span>mean(cross_val_accuracy)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Cross-validation evaluation:
Cross-validated accuracy: 0.9764044943820224</code></pre>
</div>
</div>
<div id="d43d56b9" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="351">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix Display</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_predictions(labels_test, labels_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="naive_bayes_files/figure-html/cell-44-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="da47e0e1" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="359">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's Check Some Misclassified Examples</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="co"># identifying misclassified examples</span></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>misclassified_idx <span class="op">=</span> np.where(labels_pred <span class="op">!=</span> labels_test)[<span class="dv">0</span>]</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a><span class="co"># random select a misclassified example</span></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> np.random.choice(misclassified_idx)</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"True class:"</span>, labels_test.iloc[i])</span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicted class:"</span>, labels_pred[i])</span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a><span class="co"># The specific element from 'features_test'</span></span>
<span id="cb59-13"><a href="#cb59-13" aria-hidden="true" tabindex="-1"></a>specific_element <span class="op">=</span> features_test.iloc[i]</span>
<span id="cb59-14"><a href="#cb59-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-15"><a href="#cb59-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the indices where the 'text' column in the DataFrame matches the specific element</span></span>
<span id="cb59-16"><a href="#cb59-16" aria-hidden="true" tabindex="-1"></a>matching_indices <span class="op">=</span> df.index[df[<span class="st">'processed_text'</span>] <span class="op">==</span> specific_element].tolist()</span>
<span id="cb59-17"><a href="#cb59-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-18"><a href="#cb59-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Print text</span></span>
<span id="cb59-19"><a href="#cb59-19" aria-hidden="true" tabindex="-1"></a><span class="bu">list</span>(df.iloc[matching_indices,<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>True class: entertainment
Predicted class: politics</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="359">
<pre><code>['Musicians to tackle US red tape\n\nMusicians\' groups are to tackle US visa regulations which are blamed for hindering British acts\' chances of succeeding across the Atlantic.\n\nA singer hoping to perform in the US can expect to pay $1,300 (£680) simply for obtaining a visa. Groups including the Musicians\' Union are calling for an end to the "raw deal" faced by British performers. US acts are not faced with comparable expense and bureaucracy when visiting the UK for promotional purposes.\n\nNigel McCune from the Musicians\' Union said British musicians are "disadvantaged" compared to their US counterparts. A sponsor has to make a petition on their behalf, which is a form amounting to nearly 30 pages, while musicians face tougher regulations than athletes and journalists. "If you make a mistake on your form, you risk a five-year ban and thus the ability to further your career," says Mr McCune.\n\n"The US is the world\'s biggest music market, which means something has to be done about the creaky bureaucracy," says Mr McCune. "The current situation is preventing British acts from maintaining momentum and developing in the US," he added.\n\nThe Musicians\' Union stance is being endorsed by the Music Managers\' Forum (MMF), who say British artists face "an uphill struggle" to succeed in the US, thanks to the tough visa requirements, which are also seen as impractical. The MMF\'s general secretary James Seller said: "Imagine if you were an orchestra from the Orkneys? Every member would have to travel to London to have their visas processed."\n\n"The US market is seen as the holy grail and one of the benchmarks of success, and we\'re still going to fight to get in there. "It\'s still very important, but there are other markets like Europe, India and China," added Mr Seller. A Department for Media, Culture and Sport spokeswoman said: "We\'re aware that people are experiencing problems, and are working with the US embassy and record industry to see what we can do about it." A US Embassy spokesman said: "We are aware that entertainers require visas for time-specific visas and are doing everything we can to process those applications speedily." "We are aware of the importance of cultural exchange and we will do our best to facilitate that," he added.']</code></pre>
</div>
</div>
<div id="e70c3678" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="360">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, let's check the features most associated with each label</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the feature names</span></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> pipeline.named_steps[<span class="st">'countvectorizer'</span>].get_feature_names_out()</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the log probability of features given a class</span></span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>feature_log_prob <span class="op">=</span> pipeline.named_steps[<span class="st">'multinomialnb'</span>].feature_log_prob_</span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Associate feature names with log probabilities</span></span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>feature_prob <span class="op">=</span> {}</span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, label <span class="kw">in</span> <span class="bu">enumerate</span>(pipeline.named_steps[<span class="st">'multinomialnb'</span>].classes_):</span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a>    sorted_features <span class="op">=</span> np.argsort(feature_log_prob[i])</span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a>    feature_prob[label] <span class="op">=</span> <span class="bu">list</span>(<span class="bu">zip</span>(feature_names[sorted_features], feature_log_prob[i][sorted_features]))</span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the features most associated with each label</span></span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> label, features <span class="kw">in</span> feature_prob.items():</span>
<span id="cb62-17"><a href="#cb62-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Label: </span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb62-18"><a href="#cb62-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Top 10 features associated:"</span>)</span>
<span id="cb62-19"><a href="#cb62-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> feature, log_prob <span class="kw">in</span> features[<span class="op">-</span><span class="dv">10</span>:]:  <span class="co"># Last 10 features have the highest log probabilities</span></span>
<span id="cb62-20"><a href="#cb62-20" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>np<span class="sc">.</span>exp(log_prob)<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># Convert log prob to actual probability</span></span>
<span id="cb62-21"><a href="#cb62-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb62-22"><a href="#cb62-22" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Label: business
Top 10 features associated:
bank: 0.0037926675094816717
also: 0.0039506953223767405
would: 0.0040349768225874435
market: 0.004614412136536034
firm: 0.0050042140750105385
mr: 0.00556257901390645
compani: 0.005583649388959127
us: 0.007237673830594187
year: 0.007469447956173624
said: 0.01455962916139909


Label: entertainment
Top 10 features associated:
also: 0.0040423509885020555
one: 0.0040825067930236
show: 0.004417138497369795
star: 0.004832081810759077
music: 0.005943059069188452
award: 0.005996600141883843
best: 0.006331231846230038
year: 0.006732789891445477
said: 0.00904844128552116
film: 0.01062790293003521


Label: politics
Top 10 features associated:
blair: 0.004841149773071103
peopl: 0.00492461787260681
say: 0.005039386509468409
parti: 0.00570713130575408
elect: 0.005801032917731752
labour: 0.00606187072878084
govern: 0.00616620585320048
would: 0.008430278053106572
mr: 0.013761802910949967
said: 0.017903907350409514


Label: sport
Top 10 features associated:
time: 0.0035177376478137297
would: 0.0038041983683197336
first: 0.0038844073700614145
year: 0.003907324227701897
england: 0.004067742231185259
player: 0.004514620955174626
win: 0.005351086259052158
game: 0.00562608855073792
play: 0.005717755981299843
said: 0.008639655330461087


Label: tech
Top 10 features associated:
new: 0.003904219014397402
also: 0.0039798455328360904
servic: 0.004093285310494126
phone: 0.004168911828932817
mobil: 0.004480871217492418
technolog: 0.005019710161368087
game: 0.0067213068262386225
peopl: 0.007401945492186837
use: 0.007638278362307745
said: 0.01240274902394525

</code></pre>
</div>
</div>
<div id="64ed9cfd" class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>XXXX Parei aqui <span class="op">!!!</span> XXXXX</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.datasets <span class="im">import</span> mnist</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>(x_train, y_train), (x_test, y_test) <span class="op">=</span> mnist.load_data()</span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>x_train.shape, y_train.shape</span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>x_test.shape, y_test.shape</span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a>plt.imshow(x_train[<span class="dv">5</span>], cmap<span class="op">=</span><span class="st">'gray'</span>)<span class="op">;</span></span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-15"><a href="#cb64-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-16"><a href="#cb64-16" aria-hidden="true" tabindex="-1"></a>x_train <span class="op">=</span> x_train.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">784</span>)</span>
<span id="cb64-17"><a href="#cb64-17" aria-hidden="true" tabindex="-1"></a>x_test <span class="op">=</span> x_test.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">784</span>)</span>
<span id="cb64-18"><a href="#cb64-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-19"><a href="#cb64-19" aria-hidden="true" tabindex="-1"></a>x_train.shape, x_test.shape</span>
<span id="cb64-20"><a href="#cb64-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-21"><a href="#cb64-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB, BernoulliNB</span>
<span id="cb64-22"><a href="#cb64-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-23"><a href="#cb64-23" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> GaussianNB(var_smoothing<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb64-24"><a href="#cb64-24" aria-hidden="true" tabindex="-1"></a>model.fit(X_train, y_train)</span>
<span id="cb64-25"><a href="#cb64-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"train acc:"</span>, model.score(X_train, y_train))</span>
<span id="cb64-26"><a href="#cb64-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"test acc:"</span>, model.score(X_test, y_test))</span>
<span id="cb64-27"><a href="#cb64-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-28"><a href="#cb64-28" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> BernoulliNB()</span>
<span id="cb64-29"><a href="#cb64-29" aria-hidden="true" tabindex="-1"></a>model.fit(X_train, y_train)</span>
<span id="cb64-30"><a href="#cb64-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"train acc:"</span>, model.score(X_train, y_train))</span>
<span id="cb64-31"><a href="#cb64-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"test acc:"</span>, model.score(X_test, y_test))</span>
<span id="cb64-32"><a href="#cb64-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-33"><a href="#cb64-33" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb64-34"><a href="#cb64-34" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb64-35"><a href="#cb64-35" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb64-36"><a href="#cb64-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-37"><a href="#cb64-37" aria-hidden="true" tabindex="-1"></a>p_test <span class="op">=</span> model.predict(X_test)</span>
<span id="cb64-38"><a href="#cb64-38" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_predictions(y_test, p_test)<span class="op">;</span></span>
<span id="cb64-39"><a href="#cb64-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-40"><a href="#cb64-40" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1</span>)</span>
<span id="cb64-41"><a href="#cb64-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-42"><a href="#cb64-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Show some misclassified examples</span></span>
<span id="cb64-43"><a href="#cb64-43" aria-hidden="true" tabindex="-1"></a>misclassified_idx <span class="op">=</span> np.where(p_test <span class="op">!=</span> y_test)[<span class="dv">0</span>]</span>
<span id="cb64-44"><a href="#cb64-44" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> np.random.choice(misclassified_idx)</span>
<span id="cb64-45"><a href="#cb64-45" aria-hidden="true" tabindex="-1"></a>plt.imshow(X_test[i].reshape(<span class="dv">28</span>, <span class="dv">28</span>), cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb64-46"><a href="#cb64-46" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"True label: </span><span class="sc">{</span>y_test[i]<span class="sc">}</span><span class="ss"> Predicted: </span><span class="sc">{</span>p_test[i]<span class="sc">}</span><span class="ss">"</span>)<span class="op">;</span></span>
<span id="cb64-47"><a href="#cb64-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-48"><a href="#cb64-48" aria-hidden="true" tabindex="-1"></a><span class="co"># loop through each class</span></span>
<span id="cb64-49"><a href="#cb64-49" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">10</span>):</span>
<span id="cb64-50"><a href="#cb64-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># get only the samples belonging to this class</span></span>
<span id="cb64-51"><a href="#cb64-51" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> X_train[y_train <span class="op">==</span> c]</span>
<span id="cb64-52"><a href="#cb64-52" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb64-53"><a href="#cb64-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># check which have zero variance</span></span>
<span id="cb64-54"><a href="#cb64-54" aria-hidden="true" tabindex="-1"></a>    variances <span class="op">=</span> np.var(x, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb64-55"><a href="#cb64-55" aria-hidden="true" tabindex="-1"></a>    idx_zero_var <span class="op">=</span> np.where(variances <span class="op">==</span> <span class="dv">0</span>)[<span class="dv">0</span>]</span>
<span id="cb64-56"><a href="#cb64-56" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb64-57"><a href="#cb64-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set those indices to 1</span></span>
<span id="cb64-58"><a href="#cb64-58" aria-hidden="true" tabindex="-1"></a>    zero_variances[idx_zero_var] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb64-59"><a href="#cb64-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-60"><a href="#cb64-60" aria-hidden="true" tabindex="-1"></a><span class="co"># how many columns can we remove?</span></span>
<span id="cb64-61"><a href="#cb64-61" aria-hidden="true" tabindex="-1"></a>zero_variances.<span class="bu">sum</span>()</span>
<span id="cb64-62"><a href="#cb64-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-63"><a href="#cb64-63" aria-hidden="true" tabindex="-1"></a>X_train2 <span class="op">=</span> X_train[:, <span class="op">~</span>zero_variances]</span>
<span id="cb64-64"><a href="#cb64-64" aria-hidden="true" tabindex="-1"></a>X_test2 <span class="op">=</span> X_test[:, <span class="op">~</span>zero_variances]</span>
<span id="cb64-65"><a href="#cb64-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-66"><a href="#cb64-66" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> GaussianNB()</span>
<span id="cb64-67"><a href="#cb64-67" aria-hidden="true" tabindex="-1"></a>model.fit(X_train2, y_train)</span>
<span id="cb64-68"><a href="#cb64-68" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"train acc:"</span>, model.score(X_train2, y_train))</span>
<span id="cb64-69"><a href="#cb64-69" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"test acc:"</span>, model.score(X_test2, y_test))</span>
<span id="cb64-70"><a href="#cb64-70" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="not-covered-in-the-lecture" class="level1">
<h1>Not covered in the lecture:</h1>
<ul>
<li>Complement Naive Bayes</li>
<li>Categorical Naive Bayes</li>
<li>Out-of-core naive Bayes model fitting</li>
</ul>
<p><strong>References</strong></p>
<p><br></p>
<ul>
<li>H. Zhang (2004). <a href="https://www.cs.unb.ca/~hzhang/publications/FLAIRS04ZhangH.pdf">The optimality of Naive Bayes.</a> Proc. FLAIRS.<br>
</li>
<li>C.D. Manning, P. Raghavan and H. Schütze (2008). Introduction to Information Retrieval. Cambridge University Press, pp.&nbsp;234-265.<br>
</li>
<li>A. McCallum and K. Nigam (1998). <a href="https://citeseerx.ist.psu.edu/doc_view/pid/04ce064505b1635583fa0d9cc07cac7e9ea993cc">A comparison of event models for Naive Bayes text classification.</a> Proc. AAAI/ICML-98 Workshop on Learning for Text Categorization, pp.&nbsp;41-48.<br>
</li>
<li>V. Metsis, I. Androutsopoulos and G. Paliouras (2006). <a href="https://citeseerx.ist.psu.edu/doc_view/pid/8bd0934b366b539ec95e683ae39f8abb29ccc757">Spam filtering with Naive Bayes – Which Naive Bayes?</a> 3rd Conf. on Email and Anti-Spam (CEAS).<br>
</li>
<li>Rennie, J. D., Shih, L., Teevan, J., &amp; Karger, D. R. (2003). <a href="https://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf">Tackling the poor assumptions of naive bayes text classifiers.</a> In ICML (Vol. 3, pp.&nbsp;616-623).<br>
</li>
<li>C.D. Manning, P. Raghavan and H. Schütze (2008). Introduction to Information Retrieval. Cambridge University Press, pp.&nbsp;234-265.<br>
</li>
<li>A. McCallum and K. Nigam (1998). <a href="https://citeseerx.ist.psu.edu/doc_view/pid/04ce064505b1635583fa0d9cc07cac7e9ea993cc">A comparison of event models for Naive Bayes text classification.</a> Proc. AAAI/ICML-98 Workshop on Learning for Text Categorization, pp.&nbsp;41-48.<br>
</li>
<li>V. Metsis, I. Androutsopoulos and G. Paliouras (2006). <a href="https://citeseerx.ist.psu.edu/doc_view/pid/8bd0934b366b539ec95e683ae39f8abb29ccc757">Spam filtering with Naive Bayes – Which Naive Bayes?</a> 3rd Conf. on Email and Anti-Spam (CEAS).<br>
</li>
<li>Rennie, J. D., Shih, L., Teevan, J., &amp; Karger, D. R. (2003). <a href="https://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf">Tackling the poor assumptions of naive bayes text classifiers.</a> In ICML (Vol. 3, pp.&nbsp;616-623).<br>
</li>
<li>Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., &amp; Johannes, R.S. (1988). <em>Using the ADAP learning algorithm to forecast the onset of diabetes mellitus</em>. In Proceedings of the Symposium on Computer Applications and Medical Care (pp.&nbsp;261–265). IEEE Computer Society Press.</li>
<li>D. Greene and P. Cunningham. “Practical Solutions to the Problem of Diagonal Dominance in Kernel Document Clustering”, Proc. ICML 2006.</li>
</ul>
</section>
<section id="annex" class="level1">
<h1>Annex</h1>
<section id="complement-naive-bayes" class="level2">
<h2 class="anchored" data-anchor-id="complement-naive-bayes">Complement Naive Bayes</h2>
<p><code>ComplementNB</code> implements the complement naive Bayes (CNB) algorithm. CNB is an adaptation of the standard multinomial naive Bayes (MNB) algorithm that is particularly suited for imbalanced data sets. Specifically, CNB uses statistics from the <em>complement</em> of each class to compute the model’s weights. The inventors of CNB show empirically that the parameter estimates for CNB are more stable than those for MNB. Further, CNB regularly outperforms MNB (often by a considerable margin) on text classification tasks.</p>
<p><strong>Weights calculation</strong></p>
<p>The procedure for calculating the weights is as follows:</p>
<p><span class="math display">\[
\hat{\theta}_{ci} = \frac{\alpha_i + \sum_{j:y_j \neq c} d_{ij}}
                         {\alpha + \sum_{j:y_j \neq c} \sum_{k} d_{kj}}
\]</span> <span class="math display">\[
w_{ci} = \log \hat{\theta}_{ci}
\]</span> <span class="math display">\[
w_{ci} = \frac{w_{ci}}{\sum_{j} |w_{cj}|}
\]</span></p>
<p>where the summations are over all documents $ j $ not in class $ c <span class="math inline">\(,\)</span> d_{ij} $ is either the count or tf-idf value of term $ i $ in document $ j $, $ <em>i $ is a smoothing hyperparameter like that found in MNB, and $ = </em>{i} _i $. The second normalization addresses the tendency for longer documents to dominate parameter estimates in MNB. The classification rule is:</p>
<p><span class="math display">\[
\hat{c} = \arg\min_c \sum_{i} t_i w_{ci}
\]</span></p>
<p>i.e., a document is assigned to the class that is the <em>poorest</em> complement match.</p>
</section>
<section id="categorical-naive-bayes" class="level2">
<h2 class="anchored" data-anchor-id="categorical-naive-bayes">Categorical Naive Bayes</h2>
<p><code>CategoricalNB</code> implements the categorical naive Bayes algorithm for categorically distributed data. It assumes that each feature, which is described by the index $ i $, has its own categorical distribution.</p>
<p>For each feature $ i $ in the training set $ X <span class="math inline">\(,
`CategoricalNB` estimates a categorical distribution for each feature i
of X conditioned on the class y. The index set of the samples is defined as\)</span> J = { 1, , m } $, with $ m $ as the number of samples.</p>
<p><strong>Probability calculation</strong></p>
<p>The probability of category $ t $ in feature $ i $ given class $ c $ is estimated as:</p>
<p><span class="math display">\[
P(x_i = t \mid y = c \: ;\, \alpha) = \frac{ N_{tic} + \alpha}{N_{c} +
                                       \alpha n_i},
\]</span></p>
<p>where $ N_{tic} = |{j J x_{ij} = t, y_j = c}| $ is the number of times category $ t $ appears in the samples $ x_{i} $, which belong to class $ c $, $ N_{c} = |{ j Jy_j = c}| $ is the number of samples with class c, $ $ is a smoothing parameter and $ n_i $ is the number of available categories of feature $ i $.</p>
<p><code>CategoricalNB</code> assumes that the sample matrix $ X $ is encoded (for instance with the help of <code>OrdinalEncoder</code>) such that all categories for each feature $ i $ are represented with numbers $ 0, …, n_i - 1 $ where $ n_i $ is the number of available categories of feature $ i $.</p>
</section>
<section id="out-of-core-naive-bayes-model-fitting" class="level2">
<h2 class="anchored" data-anchor-id="out-of-core-naive-bayes-model-fitting">Out-of-core naive Bayes model fitting</h2>
<p>Naive Bayes models can be used to tackle large scale classification problems for which the full training set might not fit in memory. To handle this case, <code>MultinomialNB</code>, <code>BernoulliNB</code>, and <code>GaussianNB</code> expose a <code>partial_fit</code> method that can be used incrementally as done with other classifiers as demonstrated in sphx_glr_auto_examples_applications_plot_out_of_core_classification.py. All naive Bayes classifiers support sample weighting.</p>
<p>Contrary to the <code>fit</code> method, the first call to <code>partial_fit</code> needs to be passed the list of all the expected class labels.</p>
<p>For an overview of available strategies in scikit-learn, see also the out-of-core learning documentation.</p>
<blockquote class="blockquote">
<p><strong>Note</strong></p>
<p>The <code>partial_fit</code> method call of naive Bayes models introduces some computational overhead. It is recommended to use data chunk sizes that are as large as possible, that is as the available RAM allows.</p>
</blockquote>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>